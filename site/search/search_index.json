{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["trimmer","stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>An open-source software to sort clinical data into a BIDS compliant structure</p> <p>Currently, data2bids will convert EDF/EDF+ and DICOM file formats into a Brain Imaging Data Structure compliant format.</p> <p></p>"},{"location":"index.html#european-data-format-edf","title":"European Data Format (EDF)","text":"<p>The European Data Format (EDF) is a simple and flexible format for exchange and storage of multichannel biological and physical signals. It was developed by a few European medical engineers who first met at the 1987 international Sleep Congress in Copenhagen. In March 1990, they agreed upon a very simple file format to exchange their sleep recordings. This format became known as the European Data Format.</p> <p>An extension of EDF, named EDF+, was developed in 2002 and is largely compatible to EDF. However, the EDF+ format provides a few advantages: the files can contain interrupted recordings, annotations can be stored within the file along with stimuli/events. Medical type recordings often contain annotations about patient events, stimulation responses and are often discontinuous as the patient may require breaks during recording time. EDF+ allows for these medical type recordings to be stored much easier. </p> <p>The full specifications can be found on the EDF website. The site also supports users and developers by offering free downloads of files and software, a list of EDF(+) compatible companies and further contact possibilities.</p>"},{"location":"index.html#edf-file-structure","title":"EDF File Structure","text":"<p>EDF/EDF+ files consist of a header (ascii) that describes the contents of the file and the experimental settings. The data (int16) are stored after the header.</p>"},{"location":"index.html#the-header","title":"The Header","text":"<p>The EDF/EDF+ header is split into two parts: measurement info and channel info. The measurement info contains general information about the recording while the channel info contains specific information about each channel used to record. Thus, the length of the full header (the \u2018header record\u2019) equals:</p> <p> <p><code>measurement info (256) + channel info (number of channels * 256)</code></p> <p></p> <p>The header record is ascii only, and contains the following fields:</p>"},{"location":"index.html#measurement-info","title":"Measurement Info","text":"<p>The first 256 bytes in an EDF/EDF+ file is allocated to the measurement info (i.e. patient info, date and time of data acquisition, etc.).</p> <p> Field Size Position Notes version 8 0 <code>version</code> is always 0 patient id 80 8 Code Sex DOB Name<sup>1</sup> recording id 80 88 Startdate start_date ExpID InvestigID Equipment<sup>2</sup> startdate 8 168 dd.mm.yy starttime 8 176 hh.mm.ss number of bytes in header 8 184 reserved 44 192 <ul><li>EDF: empty</li><li>EDF+: <code>EDF+C</code> for continuous;<code>EDF+D</code> for discontinuous</li></ul> number of data records 8 236 <code>nr</code> duration of data record 8 244 in seconds number of signals 4 252 <code>ns</code> total 256 <p></p> <sup>1</sup> patient id <ul> <li>Code: hospital subject code</li> <li>Sex: F or M</li> <li>DOB: birthdate in dd-MMM-yyyy</li> <li>Name: the patients name</li> </ul> <p>e.g. <code>MCH-0234567 F 02-MAY-1951 Haagse_Harry</code></p> <sup>2</sup> recording id <ul> <li>Startdate: the text <code>Startdate</code></li> <li>start_date: start date itself in dd-MMM-yyyy</li> <li>InvestigID: a code specifying the technition/clinician</li> <li>Equipment: a code specifying used equipment</li> </ul> <p>e.g. <code>Startdate 02-MAR-2002 PSG-1234/2002 NN Telem03</code></p>"},{"location":"index.html#channel-info","title":"Channel Info","text":"<p>The channel info record is 256 bytes and each channel has its own channel info record. For instance, if 10 channels are used to record then there would be 10 * channel info records within the EDF/EDF+ header. For each channel, the following information is stored:</p> <p> Field Size Position Notes label 16 0 transducer 80 16 <code>transducer</code> type (i.e AgAgCl electrode) physical dim 8 96 physical dimension of channel data (i.e. \u03bcV) physical min 8 104 physical max 8 112 digital min 8 120 <sup>1</sup> digital max 8 128 <sup>1</sup> prefiltering 80 136 high-pass, low-pass and notch filters<sup>2</sup> number of samples 8 216 reserved 32 224 total 256 <p></p> <sup>1</sup> digital min/max <ul> <li>digital range must be somewhere between -32768 and 32767 (because data samples are 16-bit signed integers)</li> </ul> <sup>2</sup> prefiltering <ul> <li>HighPass: HP</li> <li>LowPass: LP</li> <li>Notch: N</li> </ul> <p>e.g. <code>HP:0.1Hz LP:75Hz N:60Hz</code></p> <p>After the channel info header blocks there are 256 bytes for each channel acquired.</p> <p>Note</p> <p>each field in the channel info record holds the values for all channels (rather than the header storing one full channel record, then a second full channel record, etc). That is, if e.g. two channels are acquired, then there will be two consecutive <code>label</code> fields (16 + 16 bytes), then two consecutive <code>transducer</code> fields (80 + 80 bytes), then two <code>physical dim</code> fields (8 + 8 bytes), etc.</p>"},{"location":"index.html#data-record","title":"Data Record","text":"<p>Data records follow after the header record. Here, data samples (of type int16) are stored in blocks ('data record'). Each block contains the samples acquired during a period of time specified in the header as <code>duration of data record</code>, and the total number of blocks in the file are <code>number of data records</code>.</p> <p>Note</p> <p>Note that EDF allows the acquisition of signals at different sampling rates; the number of samples per signal in each data block is in the signal header as <code>number of samples in data record</code>.</p> <p>For example, two signals signal_A and signal_B are acquired at 100 Hz and 5 Hz respectively. The data are saved every 20 seconds (<code>duration of data record</code> = 20). Thus, one block of data (a data record)will consist of 2000 samples (<code>number of samples in data record</code> = 100 Hz * 20 secs = 2000) from signal_A followed by 100 samples (<code>number of samples in data record</code> = 5 Hz * 20 seconds = 100) from signal_B. If the header indicates that there are 70 such blocks (<code>number of data records = 70</code>), then the total duration of the recording would be 70 x 20 = 1400 seconds (<code>number of data records</code> * <code>duration of data record</code>).</p>"},{"location":"index.html#edf-file-structure-diagram","title":"EDF File Structure Diagram","text":""},{"location":"installation.html","title":"Installation","text":"<p>There are a few ways to install data2bids. For those looking to simply run the software you should install a compiled version. Currently, the software comes pre-compiled for Windows 10 systems.</p>"},{"location":"installation.html#windows","title":"Windows","text":"<p>For 64-bit Windows, compiled version can be found in this google drive folder. Make sure to download the latest version, the zipped folders contain the date of compiling.</p>"},{"location":"installation.html#compile-from-source","title":"Compile from source","text":"<p>For users wanting to compile the source code, you can obtain the code from the GitHub repository.</p>"},{"location":"installation.html#python-setup","title":"Python Setup","text":"<p>First you will need to install Python, depending on what operating system you are using there are different approaches.</p>"},{"location":"installation.html#windows_1","title":"Windows","text":"<ol> <li>You will need to download the windows python installer.</li> <li>Underneath the heading at the top that says Python Releases for Windows, click on the link for the Latest Python 3 Release - Python 3.x.x</li> <li>Scroll to the bottom and select either Windows x86-64 executable installer for 64-bit or Windows x86 executable installer for 32-bit</li> <li>Install by double-clicking on the downloaded file.</li> </ol>"},{"location":"installation.html#mac","title":"Mac","text":"<ol> <li> <p>Install Homebrew by opening a Terminal window and pasting the following line. </p> <pre><code>/usr/bin/ruby -e $(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\n</code></pre> </li> <li> <p>Homebrew asks you to enter your password so it can finalize the installation. Enter your user account password and hit enter</p> </li> <li> <p>Once Homebrew has finished installing, return to your terminal and run the following command:</p> <pre><code>brew install python3\n</code></pre> </li> </ol>"},{"location":"installation.html#linux","title":"Linux","text":"<ol> <li> <p>Open a terminal window and run the following commands:</p> <pre><code>sudo apt-get install python3.6\nsudo apt install python3-pip\n</code></pre> </li> </ol>"},{"location":"installation.html#compiling","title":"Compiling","text":"<ol> <li> <p>Make a directory on your computer to store the source code:</p> <pre><code>mkdir /Documents/software\n</code></pre> </li> <li> <p>Clone a copy of the data2bids repository to your system:</p> <pre><code>cd /Documents/software\ngit clone https://github.com/greydongilmore/data2bids.git\n</code></pre> </li> <li> <p>Install the Python dependencies by opening a terminal, changing to the project directory and running:</p> <pre><code>cd /data2bids\npython3 -m pip install -r requirements.txt\n</code></pre> </li> <li> <p>Once you have installed the dependencies, you can run the program from the Terminal (from within the data2bids directory):</p> <pre><code>python3 main.py\n</code></pre> </li> <li> <p>To compile data2bids for your platform, you can run the following:</p> <pre><code>python3 setup.py build_exe\n</code></pre> </li> </ol>"},{"location":"installation.html#other-useful-software","title":"Other Useful Software","text":""},{"location":"installation.html#edfbrowser","title":"EDFBrowser","text":"<p>EDFBrowser (developed by Teunis van Beelen) is a free, open-source, viewer/toolbox for EEG/IEEG data. It is a great tool to use when attempting to organize your input directory for data2bids.</p>"},{"location":"installation.html#windows_2","title":"Windows","text":"<p>For 64-bit windows download this file.</p> <p>For 32-bit Windows download this file.</p>"},{"location":"installation.html#mac_1","title":"Mac","text":"<p>You can download the latests <code>.dmg</code> file from this website.</p>"},{"location":"installation.html#linux_1","title":"Linux","text":"<p>To install on Linux, you must first have the dependencies installed (<code>g++</code>, <code>Qt5</code>):</p> <pre><code>sudo apt-get update\nsudo apt-get install g++ make git qtbase5-dev-tools qtbase5-dev qt5-default\n</code></pre> <p>Then enter the following commands to download and install:</p> <pre><code>git clone https://gitlab.com/Teuniz/EDFbrowser.git\ncd EDFbrowser\nqmake\nmake -j4\nsudo make install\nedfbrowser\n</code></pre> <p></p>"},{"location":"manuals.html","title":"Product Manuals","text":""},{"location":"manuals.html#natus","title":"Natus","text":""},{"location":"manuals.html#neuroworks","title":"NeuroWorks","text":"<ul> <li>NeuroWorks Version 9 (2018) User Manual</li> <li>NeuroWorks Version 8 (2015) User Manual</li> </ul>"},{"location":"manuals.html#quantum-headbox","title":"Quantum headbox","text":"<ul> <li>Quantum 64 (2018) User Manual</li> </ul>"},{"location":"manuals.html#seeg-electrodes","title":"SEEG Electrodes","text":""},{"location":"manuals.html#adtech","title":"AdTech","text":"<ul> <li>2019 Product Manual</li> <li>2016 Product Manual</li> <li>2015 Product Manual</li> </ul>"},{"location":"manuals.html#dixi-medical","title":"DIXI Medical","text":"<ul> <li>DIXI Product Manual (CA-E2-HD)</li> <li>DIXI Microdeep Lengths Reference</li> <li>DIXI Microdeep Accessories (MU-5100-02-R07)</li> </ul>"},{"location":"manuals.html#pmt","title":"PMT","text":"<ul> <li>2015 Product Manual</li> <li>2014 Product Manual</li> </ul>"},{"location":"manuals.html#alcis-neuro","title":"ALCIS Neuro","text":"<ul> <li>Product catalog 2021</li> </ul>"},{"location":"manuals.html#neuropace","title":"Neuropace","text":"<ul> <li>Product catalog 2019</li> </ul>"},{"location":"manuals.html#mri","title":"MRI","text":""},{"location":"manuals.html#clinical","title":"Clinical","text":"<ul> <li>2021 LHSC Epilepsy pre-op - GE 1.5T</li> <li>2018 LHSC Epilepsy pre-op - GE 1.5T</li> <li>2019 LHSC Epilepsy post-op - GE 1.5T</li> </ul>"},{"location":"manuals.html#cfmm-research","title":"CFMM Research","text":"<ul> <li>2024 CFMM DBS pre-op - Siemens 7T</li> <li>2023 CFMM DBS pre-op - Siemens 3T</li> <li>2021 CFMM Epilepsy pre-op - Siemens 7T</li> </ul>"},{"location":"manuals.html#edfbrowser","title":"EDFbrowser","text":"<ul> <li>EDFbrowser software manual</li> </ul>"},{"location":"manuals.html#neuronavigation","title":"Neuronavigation","text":""},{"location":"manuals.html#brainlab","title":"Brainlab","text":"<ul> <li>Brainab Elements Trajectory Planning v2.5</li> <li>Brainab Cranial Navigation System v1.4</li> <li>Brainab Automatic Registration v2.5</li> <li>Brainab Lead Localization v1.1</li> <li>Brainab iPlan Stereotaxy v3.0</li> </ul>"},{"location":"manuals.html#renishaw","title":"Renishaw","text":"<ul> <li>Neuromate product brochure 2014</li> </ul>"},{"location":"manuals.html#stereotactic-systems","title":"Stereotactic Systems","text":""},{"location":"manuals.html#leksell-stereotactic-system","title":"Leksell Stereotactic System","text":"<ul> <li>User manual 1007063 Rev. 04 (2015-05)</li> </ul>"},{"location":"manuals.html#crw-stereotactic-system","title":"CRW Stereotactic System","text":"<ul> <li>CRW manual 2010</li> <li>CRW product catalog 2017</li> <li>CRW product catalog 2009</li> </ul>"},{"location":"open_datasets.html","title":"Open Datasets in Electrophysiology","text":"<p>Note</p> <p>The following summary was compiled by  TomDonoghue , in this GitHub repository.</p> <p>This is a list of openly available electrophysiological data, including EEG, MEG, ECoG/iEEG, and LFP data.</p> <p>Datasets and resources listed here should all be openly-accessible for research purposes, requiring, at most, registration for access. Be sure to check the license and/or usage agreements for any datasets you access.</p> <p>To contribute a new link to a data source or resource, open an issue mentioning it, or a pull request with a link.</p>"},{"location":"open_datasets.html#table-of-contents","title":"Table of Contents","text":"<ul> <li>Data Formats</li> <li>Repositories</li> <li>EEG Data</li> <li>MEG Data</li> <li>Human Intracranial Data</li> <li>Animal LFP Data</li> <li>Behavioral Data</li> </ul>"},{"location":"open_datasets.html#data-formats","title":"Data Formats","text":"<p>The datasets listed here are not guaranteed to be in any particular format. Whenever possible, using standardized data formats can help make datasets more inter-operable.</p> <p>Standardized data formats for neurophysiological data include: - Neurodata Without Borders, or NWB, is a general data standard for neurophysiology, with the goal of promoting a common standard for storing, sharing, and archiving data. The NWB project also maintains a list of publicly available NWB datasets. - Brain Imaging Data Structure, or BIDS, is a set of data standards for imaging data, including MRI, EEG, MEG, and iEEG.</p>"},{"location":"open_datasets.html#repositories","title":"Repositories","text":"<p>There are several repositories, journals, and search engines that can be checked and searched for relevant datasets.</p>"},{"location":"open_datasets.html#neuroscience-specific-data-repositories","title":"Neuroscience Specific Data Repositories","text":"<ul> <li>OpenNeuro is a platform for analyzing and sharing neuroimaging data. Originally focused on MRI datasets, it now includes other modalities, including some electrophysiological data. Data on OpenNeuro is generally organized in BIDS formats.</li> <li>The DANDI archive ('distributed archives for neurophysiological data integration') is a platform for sharing and processing neurophysiological data. It includes a list of public datasets. Data on DANDI is generally organized in NWB format.</li> <li>The DABI repository ('data archive BRAIN initiative') is a platform for storing and processing invasive neurophysiological data, in particular for the BRAIN initiative.</li> <li>The EBrains platform for the European Union's 'Human Brain Project' includes a data portal with available data, including some extra- and intra-cranial human recordings</li> </ul>"},{"location":"open_datasets.html#general-purpose-data-repositories","title":"General Purpose Data Repositories","text":"<p>There are a few general purpose repositories that you can search for data: - Zenodo hosts datasets for individual studies. You can find available datasets by searching for 'eeg', 'meg', or similar, and selecting the 'Dataset' tag on the bottom left of the search page. - Open Science Framework is a platform for supporting open science, and includes data hosting of open-datasets for specific studies. It doesn't seem to be easily searchable by data modality in particular, but does host relevant datasets, some of which are included in the listings below. - Figshare is a general repository service for a broad range of materials, and includes datasets. You can search for resources, and select 'type' as 'Dataset' to see available datasets. - Dryad is a repository service for scientific datasets, and includes data linked to specific papers, including some EEG/MEG/ECoG datasets. There is a search function. - G-Node Open Data is a repository service for scientific datasets, by G-Node (the German Neuroinformatics Node), built on the G-Node data infrastructure services. - Harvard Dataverse is a general-purpose repository for research data, that includes some neuroscience data - Science Data Bank is a general-purpose repository for research data, that includes some neuroscience data - Kaggle is a private company that hosts data analysis competitions. These competitions typically include a dataset, and they also maintain a repository of available datasets.</p>"},{"location":"open_datasets.html#data-journals","title":"Data Journals","text":"<p>There are journals that specifically describe openly available datasets, and/or mandate that data be openly released, including:</p> <ul> <li>Scientific Data<ul> <li>A general purpose journal that publishes brief reports on openly available datasets</li> </ul> </li> <li>Data in Brief<ul> <li>A general purpose journal that publishes brief reports on openly available datasets</li> </ul> </li> <li>GigaScience<ul> <li>A general topic journal that publishes papers for which all associated data must be made available</li> <li>Data is uploaded to their GigaDB database, that is searchable</li> </ul> </li> </ul>"},{"location":"open_datasets.html#data-search-engines","title":"Data Search Engines","text":"<p>Google has a dataset search tool that can be used to search for datasets.</p>"},{"location":"open_datasets.html#eeg-data","title":"EEG Data","text":"<p>Openly available electroencephalography (EEG) datasets and large-scale projects with EEG data.</p>"},{"location":"open_datasets.html#childmind-institute","title":"ChildMind Institute","text":"<p>The ChildMind Institute is a non-profit that, amongst other things, is involved in large-scale research projects that release large datasets.</p>"},{"location":"open_datasets.html#hbn-healthy-brain-networks","title":"HBN - Healthy Brain Networks","text":"<p>A large project including rest and task EEG data across a large adult cohort (n=~1000).</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#mipdb-multimodal-resource-for-studying-information-processing-in-the-developing-brain","title":"MIPDB - Multimodal Resource for Studying Information Processing in the Developing Brain","text":"<p>A project including rest and task EEG data across a young cohort, ages 6-44 (n=126).</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#physionet","title":"Physionet","text":"<p>Physionet is an archive of physiology data, and includes some EEG data under the 'neuroelectric' tag.</p> <p>Home Page - Data Portal - Paper</p> <p>Available datasets include: - EEG Motor Movement / Imagery (n=109): Data</p>"},{"location":"open_datasets.html#predict-patient-repository-for-eeg-data-computational-tools","title":"PREDICT - Patient Repository for EEG Data + Computational Tools","text":"<p>PREDICT is a repository for EEG data, focused on patient data (collected in research settings).</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#tuh-temple-university-hospital-corpus","title":"TUH - Temple University Hospital Corpus","text":"<p>A large collection of EEG recorded in clinical settings (hospital data).</p> <p>Home Page - Data Portal - Paper</p> <p>The TUH includes multiple (described here), including: - The TUH Abnormal EEG Corpus (TUAB), with annotatations for if recordings are normal or abnormal - The TUH EEG Artifact Corpus (TUAR), with annotations of different artifacts - The TUH Epilepsy Corpus (TUEP), with a selected of subjects with and without epilepsy - The TUH EEG Events Corpus (TUEV), with annotations of specific events (sharp waves, epileptiform discharges, etc) - The TUH EEG Seizure Corpus (TUSZ), with annotations for seizures - The TUH EEG Slowing Corpus (TUSL), with annotations for slowing events</p>"},{"location":"open_datasets.html#eegbase","title":"EEGbase","text":"<p>EEGbase is a database for electrophysiological data.</p> <p>Home Page - Paper</p> <p>Note: you need to register, and the website has a 'Add to Cart' &amp; 'Complete Order' workflow, but the datasets are free.</p> <p>Available datasets include: - ERP Dataset, Visual P300 Paradigm (n=20): Paper   - Note that this data is also available on GigaDB - ERP OddBall Design, Number Guessing Game  (n=250): Paper - ERP dataset on Developmental Coordination Disorder (n=32): Paper - EEG activity using a driving simulator (n=15): Paper</p>"},{"location":"open_datasets.html#nitrc-neuroimaging-tools-resource-collaboratory","title":"NITRC - Neuroimaging Tools &amp; Resource Collaboratory","text":"<p>NITRC is a general purpose repository community board for neuroimaging tools, resources, and datasets. It is generally more focused on tools than datasets, but it does contain some available EEG datasets.</p> <p>Home Page - Paper</p> <p>Available datasets include: - Visual Oddball Task (n=18): Data - Paper - Categorization Task (n=14): Data - Resting State fMRI/EEG (n=8): Data</p>"},{"location":"open_datasets.html#erp-core","title":"ERP-CORE","text":"<p>ERP-CORE (Compendium of Open Resources and Experiments) is a resource with experiment paradigms and scripts, example data &amp; example processing scripts for ERPs, including the N170, mismatch negativity (MMN), N2pc, N400, P300, lateralized readiness potential (LRP), and error-related negativity (ERN).</p> <p>Data - Paper</p>"},{"location":"open_datasets.html#bnci-horizon-2020","title":"BNCI Horizon 2020","text":"<p>A collection of BCI related EEG datasets.</p> <p>Home Page</p>"},{"location":"open_datasets.html#mass-montreal-archive-of-sleep-studies","title":"MASS - Montreal Archive of Sleep Studies","text":"<p>MASS is a collection of whole night sleep recordings from approximately 200 participants, from hospital based sleep laboratories.</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#nsrr-national-sleep-research-resource","title":"NSRR - National Sleep Research Resource","text":"<p>NSRR is a resource offering large collections of physiological signals, including polysomnography recordings with EEG from research studies and clinical collections.</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#the-cuban-human-brain-mapping-project","title":"The Cuban Human Brain Mapping Project","text":"<p>The CHBMP is an open dataset from 282 young and middle age healthy participants, including resting state EEG, and during hyperventilation.</p> <p>Data - Paper</p>"},{"location":"open_datasets.html#lemon-leipzig-study-for-mind-body-emotion-interactions","title":"LEMON - Leipzig Study for Mind-Body-Emotion Interactions","text":"<p>A large multimodal dataset (n=228), with cross-sectional sampling of young and old participants, and including MRI, EEG, physiological, clinical and cognitive measures.</p> <p>Homepage - Data - Paper</p>"},{"location":"open_datasets.html#peers-the-penn-electrophysiology-of-encoding-and-retrieval-study","title":"PEERS - The PENN Electrophysiology of Encoding and Retrieval Study","text":"<p>A large dataset of EEG data (n&gt;300), covering 5 experiments in which subjects perform memory tasks, encoding and retrieving stimuli. </p> <p>Homepage -  Data - Paper</p>"},{"location":"open_datasets.html#lab-specific-data-collections","title":"Lab-Specific Data Collections","text":"<p>The following labs are collections of datasets from particular labs: - Narayanan lab: predominantly EEG datasets collected from humans, including Parkinson's patients: Datasets - Lab website</p>"},{"location":"open_datasets.html#individual-eeg-datasets-research-tasks-research-systems","title":"Individual EEG Datasets - Research Tasks (Research Systems)","text":"<p>The following are datasets collected with research EEG systems: - Motor Imagery BCI Data (n=52): Data - Paper - Simultaneous EEG &amp; NIRS during cognitive tasks (n=26): Data - Paper - EEG during grasp and lift (n=12): Data - Paper - EEG, MEG &amp; fMRI data with perceptual task (n=19): Data - Paper - EEG data with TMS with visual perception task (n=16): Data - Paper - EEG with Motion Capture during treadmill walking (n=8): Data - Paper - EEG data with a visual spatial attention task (n=45): Data - Paper - EEG data with a visual working memory task, ERP design (n=104): Data - Paper - EEG data with a visual working memory task, CDA design (n=76): Data - Paper - EEG data with a covert visual spatial attention task (n=50): Data - Paper - OpenMIIR: EEG data during music perception and imagination (n=10): Home Page - Data - EEG data from subjects napping after a working memory task (n=22): Data - Paper - DEAP: Database for Emotion Analysis, EEG data + video recording, while watching videos (n=32): Data - Paper - A collection of EEG tasks with speech studies (n=84, split across 5 tasks): Data - Paper - EEG recordings with concurrent EMG while doing everyday tasks (n=27): Data - Multi-modal (EEG, EMG, EOG) recordings during movement tasks (n=25): Data - Paper - EEG BCI recordings during mental imagery, across sessions &amp; interaction paradigms (n=13): Data - Paper - EEG resting state data, with MRI anatomical scans (n=12): Data - Paper - Multi-day, multi band SSVEP dataset for BCI applications (n=30): Data - Paper - Multi-day, dataset from sleep (naps) recorded after visual working memory task (n=22): Data - Paper - EEG dataset from subjects viewing images (n=24): Data - Paper - EEG data with resting state and visual working memory task (n=43): Dataset1 - Dataset2 - Paper - EEG from participants playing an 8-bit style video game (n=17): Data - Paper - An EEG/BCI dataset across multiple paradigms and recording sessions (n=54): Data - Paper - A large EEG dataset with a simple gambling task (n=500): Data - Paper - A dataset comparing different EEG systems, including 3 sessions per participant (n=14): Data - An EEG/BCI dataset for inner speech recognition (n=10): Data - Paper - An EEG/BCI sensorimotor dataset, with longitudinal data (n=62): Data - Paper - An EEG dataset of with rapid serial visual presentation (n=50): Data - Paper - A dataset of hdEEG during transcranial electrical stimulation (n=20): Data - Paper - Mobile BCI dataset of scalp and ear EEG with ERP and SSVEP paradigms while standing and moving (n=24): Data - Paper - Polysomnography dataset, including 3 EEG channels, for sleep apnea studies (n=212): Data - Paper - EEG and EMG data during perturbed walking and standing (n=30): Data - Paper - EEG data in subjects with claustrophobia, and controls, resting state in different sized rooms (n=22): Data - Paper - A dataset of arm motion in healthy and post-stroke subjects, with some EEG data (n=45 with EEG): Data - Paper - A dataset of EEG and behavioral data with a visual working memory task in virtual reality (n=47): Data - Paper - The Nencki-Symfonia EEG/ERP dataset: high-density electroencephalography (EEG) dataset obtained at the Nencki Institute of Experimental Biology from a sample of 42 healthy young adults with three cognitive tasks: (1) an extended Multi-Source Interference Task (MSIT+) with control, Simon, Flanker, and multi-source interference trials; (2) a 3-stimuli oddball task with frequent standard, rare target, and rare distractor stimuli; (3) a control, simple reaction task (SRT); and additionally (4) a resting-state protocol (REST) Data - Paper</p>"},{"location":"open_datasets.html#individual-eeg-datasets-research-tasks-consumer-systems","title":"Individual EEG Datasets - Research Tasks (Consumer Systems)","text":"<p>The following are available EEG datasets collected with consumer EEG systems: - MNIST of Brain Data from MindBigData (n=1 with 1.2 million trials): Data - ImageNet of the Brain from MindBigData (n=1 with 70,000 trials): Data</p>"},{"location":"open_datasets.html#individual-eeg-datasets-clinical-recordings","title":"Individual EEG Datasets - Clinical Recordings","text":"<p>The following are available EEG datasets collected in the context of clinical recordings / disease states: - Resting state data from Parkinson's patients, with healthy controls (n=28): Data -  Paper - Data from neonatal EEG recordings with seizure annotations (n=79): Data -  Paper - A dataset of EEG recordings from pediatric subjects with intractable seizures (n=22): Data -  Paper</p>"},{"location":"open_datasets.html#other-lists-of-eeg-data","title":"Other lists of EEG Data","text":"<p>There are some other lists of available EEG data, including: - A publicly curated list list of EEG data - The SCCN list of public EEG data</p>"},{"location":"open_datasets.html#meg-data","title":"MEG Data","text":"<p>Openly available magnetoencephalography (MEG) datasets and large-scale projects with MEG data.</p>"},{"location":"open_datasets.html#omega-open-meg-archive","title":"OMEGA - Open MEG Archive","text":"<p>OMEGA is a open-access repository for MEG data, in which individual researchers can deposit their data.</p> <p>Home Page - Paper</p>"},{"location":"open_datasets.html#hcp-human-connectome-project","title":"HCP - Human Connectome Project","text":"<p>The Human-Connectome Project is a large, multi-site project, mostly focused on MRI, that also includes a subset of MEG data.</p> <p>Home Page</p>"},{"location":"open_datasets.html#camcan-cambridge-center-for-ageing-neuroscience","title":"CAMCAN - Cambridge Center for Ageing Neuroscience","text":"<p>CAMCAN includes task &amp; rest MEG data from a large cohort, balanced in age from age 18-88 (n=652).</p> <p>Home Page</p>"},{"location":"open_datasets.html#individual-meg-datasets","title":"Individual MEG Datasets","text":"<p>The following are openly available datasets with MEG data: - 'Mother of unification studies' (MOUS) dataset, resting state and language task (n=204): Data - Paper - Classification of Multimodal Stimulus Presentation - Visual &amp; Auditory (n=52): Data - Paper - Multi-subject, multimodal face processing dataset including fMRI, MEG, EEG (n=16): Data - Paper - Decaf dataset, movie clip watching (n=30): Data - MEG data during four mental imagery tasks, for BCI analyses (n=17): Data - Paper</p>"},{"location":"open_datasets.html#human-intracranial-data","title":"Human Intracranial Data","text":"<p>This section contains intracranial EEG (iEEG) data from humans participants (collected in clinical contexts), including electrocorticography (ECoG) and stereo-EEG (sEEG) recordings, as well as any available human single unit data.</p>"},{"location":"open_datasets.html#mni-open-ieeg-atlas","title":"MNI Open iEEG Atlas","text":"<p>The MNI Open iEEG atlas is a multi-center repository of curated iEEG data, including resting state (n=106) and sleep (n=91) data.</p> <p>Home Page - Paper (rest data) - Paper (sleep data)</p>"},{"location":"open_datasets.html#ieegorg","title":"iEEG.org","text":"<p>iEEG.org is an NIH supported repository of intracranial EEG data.</p> <p>Home Page</p>"},{"location":"open_datasets.html#university-of-pennsylvania-computational-memory-lab","title":"University of Pennsylvania Computational Memory Lab","text":"<p>The cognitive electrophysiology data portal has a list of publications that have available electrophysiological data.</p> <p>Home Page</p> <p>The 'Restoring Active Memory' project is coordinate collection of ECoG data, with memory tasks (n=251).</p> <p>Home Page</p>"},{"location":"open_datasets.html#kai-millers-collection-of-ecog-data","title":"Kai Miller's Collection of ECoG Data","text":"<p>A collection of ECoG recordings, including 204 sessions from across 16 different tasks (n=34).</p> <p>Home Page - Paper</p>"},{"location":"open_datasets.html#individual-ieeg-datasets-research-recordings","title":"Individual iEEG Datasets - Research Recordings","text":"<p>The following are openly available datasets with human intracranial data: - Multicenter resting state and sleep ECoG data, annotated for artifacts (n=39): Data - Paper - ECoG data from a study looking at sensorimotor alpha and beta activity (n=3): Data - Paper - Multimodal dataset of iEEG &amp; fMRI data while watching a short movie (n=51 iEEG subjects): Data -  Paper - A dataset of long-term iEEG recordings of naturalistic data &amp; pose estimation (n=12): Data - Paper - Data from subjects with simultaneous EEG recordings and intracranial electrical stimulation (n=7): Data - Paper - Intracranial data during visual scene recognition of famous landmarks (n=50): Data - Paper - Intracranial data during memory tasks with pupillometry (n=10): Data - Paper - Intracranial data investigating responses to single-pulse stimulation (n=52): Data -  Paper</p>"},{"location":"open_datasets.html#individual-ieeg-datasets-clinical-recordings","title":"Individual iEEG Datasets - Clinical Recordings","text":"<p>The following are openly available datasets that contain seizures and/or are annotated for epilepsy: - A multicenter collection of iEEG data, including seizures (n=30): Data -  Paper - A dataset of iEEG recordings from epilepsy patients, organized in BIDS (n=12): Data -  Paper</p>"},{"location":"open_datasets.html#human-single-unit-data","title":"Human Single Unit Data","text":"<p>Available datasets with single unit data from humans: - Human single units with a declarative memory task (n=59): Data - Paper - Associated Code - Human single units with a verbal working memory task, also including iEEG data (n=9): Data - Paper - Human single units from the amygdala, with visual presentation of neutral and aversive stimuli (n=9): Data - Paper - Single unit data from neuropixel probes in human cortex (n=3): Data - Paper</p>"},{"location":"open_datasets.html#animal-lfp-data","title":"Animal LFP Data","text":"<p>Openly available animal datasets with local field potential (LFP) data, including multi-electrode arrays, animal ECoG, single-units, or similar recordings.</p>"},{"location":"open_datasets.html#neurotycho","title":"NeuroTycho","text":"<p>NeuroTycho is as collection of mostly monkey ECoG data.</p> <p>Home Page</p>"},{"location":"open_datasets.html#collaborative-research-in-computational-neuroscience-crcns","title":"Collaborative Research in Computational Neuroscience (CRCNS)","text":"<p>A collection of data, including extra-cellular recordings, and some ECoG &amp; iEEG, from various species.</p> <p>Home Page - Data Portal - Paper</p>"},{"location":"open_datasets.html#lab-specific-data-collections_1","title":"Lab-Specific Data Collections","text":"<p>The following labs are collections of datasets from particular labs:</p> <ul> <li>Buzs\u00e1ki lab: electrophysiological datasets collected from rodents: Datasets - Lab website</li> <li>Giocomo Lab: neural data recorded from rodents: Datasets - Lab website</li> </ul>"},{"location":"open_datasets.html#individual-datasets","title":"Individual Datasets","text":"<p>The following are available individual LFP and related datasets:</p> <ul> <li>LFP during during delayed reach-to-grasp task (macaque monkey, n=2): Data - Paper</li> <li>Raw LFP recordings and spiking data during anesthesia (rats, n=20): Data - Paper</li> <li>Whole-cell intracellular recordings from somatosensory cortex (mouse, n=195): Data - Paper</li> <li>High channel count (1024) Utah array recordings in macaque V1 and V4 from resting state (n=2): Data - Paper</li> </ul>"},{"location":"open_datasets.html#behavioral-data","title":"Behavioral Data","text":"<p>This list does not currently track behaviour-only data.</p> <p>See this list of available behavioral data.</p> <p> </p>"},{"location":"other_software.html","title":"Other Software","text":""},{"location":"other_software.html#table-of-contents","title":"Table of Contents","text":"<ul> <li>Relevant Software</li> <li>General Purpose Tools</li> <li>Standalone Tools</li> <li>Plugins</li> <li>Neuro Tools</li> </ul>"},{"location":"other_software.html#relevant-software","title":"Relevant Software","text":""},{"location":"other_software.html#edfbrowser","title":"EDFBrowser","text":"<p>EDFBrowser (developed by Teunis van Beelen) is a free, open-source, viewer/toolbox for EEG/IEEG data. It is a great tool to use when attempting to organize your input directory for data2bids.</p>"},{"location":"other_software.html#windows","title":"Windows","text":"<p>For 64-bit windows download this file.</p> <p>For 32-bit Windows download this file.</p>"},{"location":"other_software.html#mac","title":"Mac","text":"<p>You can download the latests <code>.dmg</code> file from this website.</p>"},{"location":"other_software.html#linux","title":"Linux","text":"<p>To install on Linux, you must first have the dependencies installed (<code>g++</code>, <code>Qt5</code>):</p> <pre><code>sudo apt-get update\nsudo apt-get install g++ make git qtbase5-dev-tools qtbase5-dev qt5-default\n</code></pre> <p>Then enter the following commands to download and install:</p> <pre><code>git clone https://gitlab.com/Teuniz/EDFbrowser.git\ncd EDFbrowser\nqmake\nmake -j4\nsudo make install\nedfbrowser\n</code></pre>"},{"location":"other_software.html#general-purpose-tools","title":"General Purpose Tools","text":"<p>Note</p> <p>The following summary was compiled by  TomDonoghue , in this GitHub repository.</p> <p>The following are general purpose platforms, with functionality including: loading data, preprocessing, visualization, standard analysis, and making figures.</p>"},{"location":"other_software.html#mne","title":"MNE","text":"<p><code>MNE</code> is a general purpose tool for processing, analyzing, and visualizing M/EEG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#neural-ensemble-tools","title":"Neural Ensemble Tools","text":"<p>Neural Ensemble is an initiative for open-source software in neuroscience and includes a set of tools for managing and analyzing electrophysiology data.</p> <p><code>neo</code> is a tool for representing electrophysiology data, and reading neurophysiological file formats.</p> <p>HomePage - Github</p> <p><code>elephant</code> is a tool for analyzing electrophysiological data.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#wonambi","title":"Wonambi","text":"<p><code>Wonambi</code> is a general purpose tool for processing, analyzing, and visualizing EEG data, including specific tools focused on sleep scoring and analysis.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#neurokit2","title":"NeuroKit2","text":"<p><code>NeuroKit2</code> is a tool for neurophysiological signal processing.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#fieldtrip","title":"FieldTrip","text":"<p><code>FieldTrip</code> is a general purpose tool for processing, analyzing, and visualizing M/EEG and iEEG/ECoG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#brainstorm","title":"BrainStorm","text":"<p><code>BrainStorm</code> is a general purpose tool for processing, analyzing and visualizing focused primarily on MEG data, with additional support for EEG &amp; ECoG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#eeglab","title":"EEGLab","text":"<p><code>EEGLab</code> is a general purpose tool for processing, analyzing, and visualizing EEG data.</p> <p>HomePage - Paper</p>"},{"location":"other_software.html#spm","title":"SPM","text":"<p><code>SPM</code> is a general purpose toolbox for neuroimaging, including support for processing M/EEG data.</p> <p>HomePage</p>"},{"location":"other_software.html#nutmeg","title":"NutMEG","text":"<p><code>NutMEG</code> is a general purpose tool for processing, analyzing, and visualizing MEG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#signaleeg","title":"Signaleeg","text":"<p><code>Signaleeg</code> is a general purpose tool for processing and analyzing EEG data, with a focus on signal-data mining.</p> <p>Code - Paper</p>"},{"location":"other_software.html#bbci-berlin-brain-computer-interface","title":"BBCI - Berlin brain-computer interface","text":"<p>The <code>BBCI</code> tool is collection of tools for online and offline analyses for brain-computer interface experiments.</p> <p>Github - Paper</p>"},{"location":"other_software.html#eegutils","title":"EEGUtils","text":"<p><code>EEGUtils</code> is a general purpose tool for processing, analyzing, and visualizing EEG data.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#eeguana","title":"EEGuana","text":"<p><code>EEGuana</code> is a package for working with EEG data.</p> <p></p> <p>HomePage - Github</p>"},{"location":"other_software.html#eegjl","title":"EEG.jl","text":"<p><code>EEG.jl</code> is library for processing EEG data.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#cartool","title":"CarTool","text":"<p><code>CarTool</code> is an EEG analysis toolbox.</p> <p>HomePage - Paper</p>"},{"location":"other_software.html#standalone-tools","title":"Standalone Tools","text":"<p>The following are standalone tools, independent of general software platforms, for specific purposes.</p>"},{"location":"other_software.html#neurodsp","title":"NeuroDSP","text":"<p><code>NeuroDSP</code> is a package for calculating a broad range of measures on neural time series, including a range of time-domain measures such as waveform shape analyses.</p> <p>Homepage - Github - Paper</p>"},{"location":"other_software.html#specparam-formerly-fooof","title":"SpecParam (formerly 'fooof')","text":"<p><code>SpecParam</code> (formerly called <code>fooof</code>) is a package for parameterizing neural power spectra.</p> <p>Homepage - Github - Paper</p>"},{"location":"other_software.html#bycycle","title":"ByCycle","text":"<p><code>ByCycle</code> is a tool for cycle-by-cycle analyses of neural oscillations.</p> <p>Homepage - Github - Paper</p>"},{"location":"other_software.html#irasa","title":"IRASA","text":"<p>A Python implementation of the 'irregular resampling auto-spectral analysis'. Note that this is a re-implementation of the algorithm described in the paper.</p> <p>Github - Paper</p>"},{"location":"other_software.html#frites-framework-for-information-theoretic-analysis-of-electrophysiological-data-and-statistics","title":"Frites - Framework for Information Theoretic analysis of Electrophysiological data and Statistics","text":"<p><code>FRITES</code> is package for computing information-theoretic measures on human and electrophysiological data.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#antropy","title":"Antropy","text":"<p><code>Antropy</code> is a package for computing entropy and complexity measures on EEG data.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#ptsa-python-time-series-analysis","title":"PTSA - Python Time Series Analysis","text":"<p><code>PTSA</code> is package for time series analysis in Python, focused on analyzing electrophysiological data.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#ghostipy-general-hub-of-spectral-techniques-in-python","title":"GhostiPy - General Hub Of Spectral Techniques In Python","text":"<p><code>Ghostipy</code> is a toolbox for signal processing and spectral analyses.</p> <p>Github - Paper</p>"},{"location":"other_software.html#spectral-connectivity","title":"Spectral Connectivity","text":"<p><code>Spectral Connectivity</code> is a package for functional connectivity and coherence related measures.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#brain-connectivity-toolbox-for-python","title":"Brain Connectivity Toolbox for Python","text":"<p>The <code>Brain Connectivity Toolbox</code> is a package for brain connectivity measures.</p> <p>Github</p>"},{"location":"other_software.html#tensor-pac","title":"Tensor PAC","text":"<p><code>TensorPAC</code> is a tool for calculating phase-amplitude coupling measures, using tensors and parallel computing.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#pactools","title":"PACTools","text":"<p><code>PACTools</code> is a package for calculating phase-amplitude coupling measures in neural time series.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#pyeeg","title":"PyEEG","text":"<p><code>PyEEG</code> includes some implementations of information theoretic and complexity related measures for neural time series.</p> <p>Github - Paper</p>"},{"location":"other_software.html#ecogtools","title":"ECoGTools","text":"<p><code>ECoGTools</code> is a collection of tools for analyzing ECoG data.</p> <p>Github</p>"},{"location":"other_software.html#eelbrain","title":"EELBrain","text":"<p><code>EELBrain</code> is a tool for statistical analysis of M/EEG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#yasa-yet-another-spindle-algorithm","title":"YASA - Yet another spindle algorithm","text":"<p><code>YASA</code> is a package for analyzing polysomnograghy recordings.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#kcsd-kernel-current-source-density","title":"kCSD - kernel Current Source Density","text":"<p>The <code>kCSD</code> tool implements kernel Current Source Density.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#emd-empirical-mode-decomposition","title":"EMD - Empirical Mode Decomposition","text":"<p>The <code>EMD</code> toolbox implements empirical mode decomposition and Hilbert-Huang spectral analyses.</p> <p>HomePage - Code - Paper</p>"},{"location":"other_software.html#ebosc-extended-better-oscillation-detector","title":"eBOSC - extended Better OSCillation detector","text":"<p><code>eBOSC</code> is a tool for oscillation detection and measurement.</p> <p>Github - Paper</p>"},{"location":"other_software.html#best-brain-electrophysiological-recording-stimulation","title":"BEST - Brain Electrophysiological recording &amp; STimulation","text":"<p><code>BEST</code> is a tool for designing and running non-invasive brain stimulation experiments.</p> <p>Homepage - Github - Paper</p>"},{"location":"other_software.html#restingiaf","title":"restingIAF","text":"<p><code>RestingIAF</code> is a tool for estimating the peak individual alpha frequency.</p> <p>Github - Paper</p>"},{"location":"other_software.html#phase-opposition-code","title":"Phase Opposition Code","text":"<p>Phase Opposition is a collection of functions for calculating phase opposition measures.</p> <p>HomePage - Paper</p>"},{"location":"other_software.html#adam-amsterdam-decoding-and-modeling-toolbox","title":"ADAM - Amsterdam Decoding and Modeling Toolbox","text":"<p><code>ADAM</code> is a tool for encoding and decoding model analysis on M/EEG data.</p> <p>Github - Paper</p>"},{"location":"other_software.html#hermes","title":"HERMES","text":"<p><code>HERMES</code> is tool for estimating connectivity measures between M/EEG signals.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#sereega-simulating-event-related-eeg-activity","title":"SEREEGA - Simulating Event-Related EEG Activity","text":"<p><code>SEREEGA</code> is a package for simulating synthetic data that mimic event-related EEG activity.</p> <p>Github - Paper</p>"},{"location":"other_software.html#unfold","title":"UNFOLD","text":"<p><code>Unfold</code> is a tool for deconvolving overlapping EEG signals and for non-linear modeling.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#ept-tfce","title":"ept-TFCE","text":"<p><code>ept-TFCE</code> is a tool for statistical analysis of already preprocessed M/EEG data, focused mainly around the 'threshold-free cluster enhancement' method.</p> <p>Github - Paper</p>"},{"location":"other_software.html#era-erp-reliability-analysis","title":"ERA - ERP Reliability Analysis","text":"<p><code>ERA</code> is a tool for calculating reliability estimates for ERP data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#synchsqueezing","title":"SynchSqueezing","text":"<p><code>SynchroSqueezing</code> is a tool for time-frequency and time-scale analyses.</p> <p>Github</p>"},{"location":"other_software.html#automagic","title":"AutoMagic","text":"<p><code>AutoMagic</code> is a standardized toolbox for preprocessing EEG datasets.</p> <p>Github - Paper</p>"},{"location":"other_software.html#mvgc-multivariate-granger-causality-toolbox","title":"MVGC - Multivariate Granger Causality Toolbox","text":"<p>The <code>MVGC</code> toolbox is designed to run Granger-causal analysis on multivariate time-series data.</p> <p>HomePage - Code - Paper</p>"},{"location":"other_software.html#openmeeg","title":"OpenMEEG","text":"<p><code>OpemMEEG</code> is a package for solving forward problems for EEG &amp; MEG data.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#plugins","title":"Plugins","text":"<p>The following are plugins, designed primary for use with one of the aforementioned general purpose tools.</p>"},{"location":"other_software.html#autoreject","title":"AutoReject","text":"<p><code>AutoReject</code> is a tool for preprocessing M/EEG data, but algorithmically determining and applying rejection thresholds, with MNE.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#mne-bids","title":"MNE-BIDS","text":"<p><code>MNE-BIDS</code> is a tool for creating BIDS compatible datasets with MNE.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#pyprep","title":"PyPREP","text":"<p><code>PrPREP</code> is an implementation of the 'Preprocessing Pipeline' (PREP) for EEG data, in Python and using MNE.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#prep-pipeline","title":"PREP Pipeline","text":"<p>The <code>PREP</code> pipeline is a standardized pre-processing tool for EEG data, using EEGLab.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#relax","title":"RELAX","text":"<p><code>RELAX</code> (Reduction of Electroencephalographic Artifacts) provides a fully automated method to clean EEG data.</p> <p>Github -  Paper1 -  Paper2</p>"},{"location":"other_software.html#adjust","title":"ADJUST","text":"<p><code>ADJUST</code> is an automatic artifact identification and removal tool, using EEGLab.</p> <p>HomePage - Paper</p>"},{"location":"other_software.html#erplab","title":"ERPlab","text":"<p><code>ERPLab</code> is a tool for event-related potential (ERP) analysis of EEG data, with EEGLab.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#limo-linear-modeling","title":"LIMO - Linear Modeling","text":"<p><code>LIMO</code> is a tool for Linear Modeling of EEG data, with EEGLab.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#sift-source-information-flow-toolbox","title":"SIFT - Source Information Flow Toolbox","text":"<p><code>SIFT</code> is a tool for causality and information flow measures, with EEGLab.</p> <p>HomePage</p>"},{"location":"other_software.html#mpt-measure-projection-toolbox","title":"MPT - Measure Projection Toolbox","text":"<p><code>MPT</code> is a tool for probabilistic multi-subject EEG independent component analysis, with EEGLab.</p> <p>HomePage</p>"},{"location":"other_software.html#neuro-tools","title":"Neuro Tools","text":"<p>The following are broader purpose neuro-tools that could be used with electrophysiology data.</p>"},{"location":"other_software.html#nibabel","title":"nibabel","text":"<p><code>nibabel</code> is a tool for read/write access to common neuroimaging file formats.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#nilearn","title":"nilearn","text":"<p><code>nilearn</code> is a tool for applying machine learning to neuroimaging data.</p> <p>HomePage - Github</p>"},{"location":"other_software.html#visbrain","title":"Visbrain","text":"<p><code>Visbrain</code> is a tool for brain data visualization.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#pycortex","title":"PyCortex","text":"<p><code>PyCortex</code> is a tool for visualizing cortical surfaces.</p> <p>Homepage - Github</p>"},{"location":"other_software.html#brainspace","title":"BrainSpace","text":"<p><code>BrainSpace</code> is a tool for analyzing gradients in neuroimaging datasets.</p> <p>HomePage - Github - Paper</p>"},{"location":"other_software.html#neuromaps","title":"neuromaps","text":"<p><code>neuromaps</code> is a tool for comparing between brain maps.</p> <p>HomePage - Github - Paper</p> <p> </p>"},{"location":"ieegProc/01_overview.html","title":"Overview","text":"<p>This section describes steps required to use ieegProc. If you have not installed ieegProc you can follow the steps in the GitHub repository.</p> <p> </p>"},{"location":"ieegProc/05_output.html","title":"None","text":""},{"location":"ieegProc/05_output.html#ieegproc-output","title":"ieegProc output","text":"<p>The output files from ieegProc conform to the BIDS Derivatives specification. In general, there are two classes of data outputs from ieegProc:</p> <ol> <li> <p>Visual QA (quality assessment): summary figures are generated throughout the pipeline so the user can confirm accuracy.</p> </li> <li> <p>Derivative (preprocessed): processed data that is ready for analysis after various preparation procedures have been applied (i.e. INU-corrected versions of the T1-weighted image, the brain mask, electrode contact coordinate files etc). All data is aligned into the same-subject\u2019s T1w space.</p> </li> </ol> <p>The ieegProc output directory has the following structure:</p> <pre><code>derivatives/\n    \u251c\u2500\u2500 atlasreg/\n    \u2502       \u251c\u2500\u2500 dataset_description.json\n    \u2502       \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n    \u2502               \u251c\u2500\u2500 qc/...\n    \u2502               \u2514\u2500\u2500 &lt;processed_files&gt;...\n    \u2502\n    \u2514\u2500\u2500 seeg_coordinates/\n            \u251c\u2500\u2500 dataset_description.json\n            \u2514\u2500\u2500 sub-P001/\n                    \u2514\u2500\u2500 &lt;processed_files&gt;...\n</code></pre> <p>For each participant in the dataset, a subject specific directory (<code>sub-&lt;subject_label&gt;</code>) will be generated in two locations:</p> <ol> <li><code>atlasreg</code>: this directory contains processed data files from the imaging analysis pipelines.</li> <li><code>seeg_coordinates</code>: this directory will store the electrode contact coordinates in several coordinate spaces (see ). </li> </ol> <p>The <code>dataset_description.json</code> is a metadata file in which ieegProc records metadata required by the BIDS standard.</p>"},{"location":"ieegProc/05_output.html#visual-qa","title":"Visual QA","text":"<p>ieegProc generates summary figures which are stored in a directory labelled <code>qc</code> within each patient directory under <code>atlasreg</code>. The figures provide a snapshot of the results from various parts of the pipeline.</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u2514\u2500\u2500 qc/...\n</code></pre>"},{"location":"ieegProc/05_output.html#atlasreg-derivatives","title":"atlasreg derivatives","text":""},{"location":"ieegProc/05_output.html#step-1-input-image-volumes","title":"Step 1: input image volumes","text":"<p>ieegProc begins by copying the relevant imaging volumes from the <code>bids</code> directory to the <code>atlasreg</code> directory. ieegProc will search for four image volumes as input. At minimum, ieegProc requires a T1w volume and a post-op CT to run.</p> <ul> <li>T1w with gadolinium</li> <li>T1w without gadolinium</li> <li>post-op CT containing electrodes/grids/strips</li> <li>PET</li> </ul> <p>After copying, each volume is renamed accordinly:</p> <ul> <li><code>sub-&lt;subject_label&gt;_acq-contrast_T1w.nii.gz</code>: T1w gad-enhanced</li> <li><code>sub-&lt;subject_label&gt;_acq-noncontrast_T1w.nii.gz</code>: T1w non-enhanced</li> <li><code>sub-&lt;subject_label&gt;_ct.nii.gz</code>: post-op CT containing electrodes/grids/strips</li> <li><code>sub-&lt;subject_label&gt;_pet.nii.gz</code>: PET</li> </ul> <p>Execpt for the filename, these volumes will remain an identical copy to the ones found in the <code>bids</code> directory.</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 qc/...\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-contrast_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-noncontrast_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_ct.nii.gz\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_pet.nii.gz\n</code></pre>"},{"location":"ieegProc/05_output.html#step-2-rigid-registration","title":"Step 2: rigid registration","text":"<p>In sterotaxy, gadolinium contrast provides simultaneous enhancement of vessels and gray/white matter contrast within a single T1w volume. Preoperative trajectory planning is done on the enhanced T1w volume. Thus, this volume is chosen first as the fixed image during registration. If an enhanced T1w volume doesn't exists, then the non-enhanced will be used as the fixed image.</p> <p>Currently, two registration algorithms are included:</p> <ol> <li><code>reg_aladin</code>: command-line function from NiftyReg, developed by Marc Modat (NiftyReg)</li> <li><code>greedy</code>: command-line function for fast image registration, developed by Paul Yushkevich (Greedy)</li> </ol> <p>For each floating volume (<code>&lt;volume_type&gt;</code>), the rigid registration step will generate the following files:</p> <ul> <li><code>sub-&lt;subject_label&gt;_space-T1w_desc-rigid_&lt;volume_type&gt;.nii.gz</code>: floating volume with the rigid transform applied without interpolation.</li> <li><code>sub-&lt;subject_label&gt;_space-T1w_desc-rigidInterp_&lt;volume_type&gt;.nii.gz</code>: floating volume with the rigid transform applied with linear interpolation.</li> <li><code>sub-&lt;subject_label&gt;_desc-rigid_from-&lt;volume_type&gt;_to-T1w_type-ras_xfm.txt</code>: rigid transform matrix from floating to fixed image space in RAS <code>.txt</code> format.</li> <li><code>sub-&lt;subject_label&gt;_desc-rigid_to-&lt;volume_type&gt;_from-T1w_type-ras_xfm.txt</code>: rigid transform matrix to floating from fixed image space in RAS <code>.txt</code> format.</li> <li><code>sub-&lt;subject_label&gt;_desc-rigid_from-&lt;volume_type&gt;_to-T1w_type-ras_xfm.tfm</code>: rigid transform matrix from floating to fixed image space in 3D Slicer <code>.tfm</code> format.</li> </ul> <p>Note</p> <p>Since there can be up to two T1w volumes, ieegProc will copy one of the volumes to a new file labelled <code>sub-&lt;subject_label&gt;_T1w.nii.gz</code>. From this point onward, any step requiring a T1w volume as input will link to this new volume. If only one T1w volume exists, then <code>sub-&lt;subject_label&gt;_T1w.nii.gz</code> will be an identical copy. If both gad-enhanced and non-enhanced T1w volumes exist then the non-enhanced volume will be copied to <code>sub-&lt;subject_label&gt;_T1w.nii.gz</code>.</p>"},{"location":"ieegProc/05_output.html#step-3-affinenon-linear-registration","title":"Step 3: affine/non-linear registration","text":"<p>ieegProc will perform template space normalization using the newly renamed T1w volume (see note above) as the floating image. For the affine registration step, either <code>reg_aladin</code> or <code>greedy</code> can be used. For the non-linear registration step, either <code>ANTS</code> or <code>greedy</code> can be used. These options can be configured in the <code>config.yml</code> file.</p> <p>After both registration steps, the following files will be generated:</p> <ul> <li><code>sub-&lt;subject_label&gt;_desc-n4_T1w.nii.gz</code>: T1w volume with <code>N4BiasFieldCorrection</code> performed.</li> <li><code>sub-&lt;subject_label&gt;_space-&lt;template_space&gt;_desc-affine_T1w.nii.gz</code>: T1w volume with affine transform applied to template space with linear interpolation.</li> <li><code>sub-&lt;subject_label&gt;_desc-affine_from-subject_to-&lt;template_space&gt;_type-ras_xfm.txt</code>: affine transform matrix from subject space to template space in RAS <code>.txt</code> format.</li> <li><code>sub-&lt;subject_label&gt;_desc-affine_to-subject_from-&lt;template_space&gt;_type-ras_xfm.txt</code>: affine transform matrix from template space to subject space in RAS <code>.txt</code> format.</li> <li><code>sub-&lt;subject_label&gt;_desc-affine_from-subject_to-&lt;template_space&gt;_type-itk_xfm.txt</code>: affine transform matrix from subject space to template space in ITK <code>.txt</code> format.</li> <li><code>sub-&lt;subject_label&gt;_desc-affine_from-subject_to-&lt;template_space&gt;_type-itk_xfm.tfm</code>: affine transform matrix from subject space to template space in 3D Slicer <code>.tfm</code> format.</li> </ul>"},{"location":"ieegProc/05_output.html#step-4-tissue-segmentation","title":"Step 4: tissue segmentation","text":"<p>ieegProc will perform image segmentation of three structures within the T1w volume: white matter, gray matter, and CSF. To improve segmenation outcomes, the chosen template space brain mask and WM/GM/CSF probabilistic tissue segmentations are warped to T1w volume space. This helps to highlight the areas that are brain and not skull/dura/etc.</p> <ul> <li><code>sub-&lt;subject_label&gt;_label-brain_desc-affine_from-&lt;template_space&gt;_mask.nii.gz</code>: template space brain mask with the affine transform applied to T1w volume space.</li> <li><code>sub-&lt;subject_label&gt;_label-&lt;CSF/WM/GM&gt;_desc-affine_from-&lt;template_space&gt;_probseg.nii.gz</code>: template space probabilistic segmentations with the affine transform applied to T1w volume space.</li> </ul> <p>After the segmentation step, the following files will be generated:</p> <ul> <li><code>sub-&lt;subject_label&gt;_desc-atropos3seg_mapping.json</code>: </li> <li><code>sub-P033_desc-atroposKseg_dseg.nii.gz</code>: </li> <li><code>sub-P033_desc-atroposKseg_probseg.nii.gz</code>:</li> </ul> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 qc/...\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-contrast_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-noncontrast_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_ct.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-noncontrast_space-T1w_desc-affine_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-MNI152NLin2009cSym_desc-affine_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-brain_from-MNI152NLin2009cSym_reg-affine_mask.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-CSF_from-MNI152NLin2009cSym_reg-affine_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-GM_from-MNI152NLin2009cSym_reg-affine_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-WM_from-MNI152NLin2009cSym_reg-affine_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_desc-affine_ct.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-ct_desc-mask_contacts.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-n4_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-atroposKseg_dseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-atroposKseg_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-CSF_desc-atropos3seg_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-GM_desc-atropos3seg_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_label-WM_desc-atropos3seg_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-atropos3seg_probseg.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-brain_from-atropos3seg_mask.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-masked_from-atropos3seg_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-MNI152NLin2009cSym_desc-SyN_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_atlas-CerebrA_from-MNI152NLin2009cSym_reg-SyN_dseg.nii.gz\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_desc-dilated_atlas-CerebrA_from-MNI152NLin2009cSym_reg-SyN_dseg.nii.gz\n</code></pre> <p>Spatially-standardized derivatives are denoted with a <code>space-</code> label. Within patient volumes are registered to the volumetric T1w so the space is denoated <code>space-T1w</code> for these volumes. Other derivatives will have been coregistered to a template space, such as <code>MNI152NLin2009cSym</code>.</p> <p>The registration transform matricies are stored in <code>.txt</code> and <code>.tfm</code> files to allow for easy loading into 3D Slicer.</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 qc/...\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-noncontrast_desc-affine_from-T1w_to-T1w_type-ras_xfm.txt\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-affine_from-subject_to-MNI152NLin2009cSym_type-itk_xfm.txt\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-affine_from-subject_to-MNI152NLin2009cSym_type-ras_xfm.txt\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-affine_from-ct_to-T1w_type-ras_xfm.txt\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_from-subject_to-MNI152NLin2009cSym_Composite.h5\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_from-subject_to-MNI152NLin2009cSym_InverseComposite.h5\n</code></pre> <p>The remaining files provide information about the pipeline.</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 qc/...\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-atropos3seg_mapping.json\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-dilated_atlas-CerebrA_from-MNI152NLin2009cSym_electrodes.tsv\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_desc-dilated_atlas-CerebrA_from-MNI152NLin2009cSym_electrodes.xlsx\n</code></pre> <p>The files within the <code>qc</code> derivatives directory are:</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 atlasreg/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u2514\u2500\u2500 qc/\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_acq-contrast_from-T1w_to-T1w_regqc.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-masked_from-ct_to-T1w_regqc.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-affine_from-subject_to-MNI152NLin2009cSym_regqc.html\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-affine_from-subject_to-MNI152NLin2009cSym_regqc.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-atropos3seg_probseg.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_atlas-CerebrA_from-MNI152NLin2009cSym_dseg.html\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_atlas-CerebrA_from-MNI152NLin2009cSym_dseg.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-dilated_atlas-CerebrA_from-MNI152NLin2009cSym_dseg.png\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-ct_desc-mask_contacts.html\n                    \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-MNI152NLin2009cSym_desc-affine_electrodes.html\n                    \u2514\u2500\u2500 sub-&lt;subject_label&gt;_space-MNI152NLin2009cSym_desc-affine_electrodevis.png\n</code></pre>"},{"location":"ieegProc/05_output.html#seeg_coordinates-derivatives","title":"seeg_coordinates derivatives","text":"<p>The files within the <code>seeg_coordinates</code> derivatives directory are:</p> <pre><code>derivatives/\n    \u2514\u2500\u2500 seeg_coordinates/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_mapping.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_mcp.tfm\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_actual.fcsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_actual.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_planned.fcsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_planned.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_SEEGA.fcsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-acpc_SEEGA.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-native_actual.fcsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-native_actual.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-native_planned.fcsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-native_planned.tsv\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-native_SEEGA.fcsv\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_space-native_SEEGA.tsv\n</code></pre>"},{"location":"ieegProc/06_qc_figs.html","title":"None","text":""},{"location":"ieegProc/06_qc_figs.html#sample-qa-figures","title":"Sample QA figures","text":""},{"location":"ieegProc/06_qc_figs.html#coregistration-of-t1w-without-contrast-to-t1wgadolinum","title":"Coregistration of T1w without contrast to T1w+gadolinum","text":""},{"location":"ieegProc/06_qc_figs.html#coregistration-of-post-op-ct-to-t1wgadolinum","title":"Coregistration of post-op CT to T1w+gadolinum","text":""},{"location":"ieegProc/06_qc_figs.html#electrode-contact-positions-in-2d-and-3d","title":"Electrode contact positions in 2D and 3D","text":""},{"location":"run_data2bids/01_overview.html","title":"Overview","text":"<p>This section describes steps required to use data2bids. If you have not installed data2bids you have two options:</p> <ul> <li>Install a compiled version</li> <li>Compile from source code</li> </ul> <p>The following steps should be taken sequentially:</p> <ol> <li>Adjust software settings (only done once at initial install)</li> <li>Export data from NeuroWorks</li> <li>Organize your input directory</li> <li>Organize imaging directory</li> <li>Check EDF file type</li> <li>Confirm input directory data</li> <li>Confirm output directory data</li> <li>Check output folder data</li> <li>Convert/Upload data to SPReD [EpLink study only]</li> </ol>"},{"location":"run_data2bids/01_overview.html#eplink-study-workflow","title":"EpLink Study Workflow","text":""},{"location":"run_data2bids/02_definitions.html","title":"Definitions","text":""},{"location":"run_data2bids/02_definitions.html#filename-terms","title":"Filename terms","text":"<p>Throughout this documentation the following filename terms will be used:</p> <p> term definition <code>sub_num</code> specific subject number <code>visit_num</code> each stay within the hospital (2 digits) <code>ses_num</code> each day spent in hospital during the visit (2 digits starting with SE, ex. SE01) <code>type</code> type of data collected (should be _IEEG/_EEG) <code>task</code> format of the edf data (should be _CLIP/_FULL/_CS) <code>RET</code> if included, indicates the study is retrospective <sup>1</sup> <p></p> <p><sup>1</sup> if not present then study assumed to be prospective (PRO), so you do not need to include this flag for prospective sessions</p> <p>Note on Visit Numbers</p> <ul> <li>If any retrospective studies exist for a subject, they should be assigned the first visit number 01</li> <li>All following admissions to the hospital would be given incremental visit numbers (i.e. visit 2: 02, visit 3: 03)</li> <li>Two separate admissions to the hospital should not have the same visit number</li> <li>Scalp and Intracranial recordings should have distinct visit numbers (ex. If 01 is used for the participant\u2019s first stay in the EMU for scalp EEG, 02 should be used if they come back for intracranial EEG)</li> </ul> <p>Note on Session Numbers</p> <p>If a day in sequence of sessions is missing/not present this session number should still be accounted for e.g.  <pre><code>ses-001 (data present), ses-002 (data missing), ses-003 (data present)\n</code></pre> The directory naming would look like: <pre><code>sub-003_01_SE01_IEEG_FULL_RET\nsub-003_01_SE03_IEEG_FULL_RET\n</code></pre> Notice that no folder is specified for the missing ses-002 but the number is still accounted for by skipping it.</p>"},{"location":"run_data2bids/02_definitions.html#data2bids-terms","title":"data2bids terms","text":"<p>Within the data2bids software, the columns present within the input/output windows are:</p> <p> term definition <code>Name</code> this is the name of the subdirectory within the patient folder that contains the EDF/EDF+ file. If the EDF/EDF+ files are all in the same directory, then the name will be the name of the EDF/EDF+ files. <code>Date</code> the date the data was recorded <code>Time</code> the time the data was recorded <code>Size</code> the size of the EDF/EDF+ file in gigabytes <code>Frequency</code> [modifiable] the frequency the data was recorded at. This is automatically calculated based on information extracted from the EDF/EDF+ file. However, if there is an error then the user can double click on the frequency box and manually change it <code>Duration</code> the total duration of the EDF/EDF+ file recording, which is automatically calculated <code>EDF Type</code> type of EDF+ file (EDF+D/EDF+C). This field should always show EDF+C, if EDF+D then the file should be converted first <code>Type</code> [selectable] the type of EEG data collected (Intracranial or Scalp). This value is automatically detected by the flags <code>_EEG/_IEEG</code> used in the directory name. This value can be changed by the user if there is an error <code>Task</code> [selectable] the condition of the recorded file: Full, clip or cortical stimulation (CS). This value is automatically detected by the flags <code>_CLIP/_FULL/_CS</code> used in the directory name. This can be changed by the user if there is an error <code>Ret/Pro</code> [selectable] whether the data file is retrospective or prospective. This value is automatically detected based on the RET flag used in the directory name. This value can be changed by the user if there is an error <code>Channel File</code> this indicates if a channel_labels.txt file was found. If you notice the labels changed in a specific session you can include a channel_label.txt file within each session folder. Yes indicates a channel label file was found, No otherwise <code>Imaging Data</code> this indicates if an <code>imaging</code> directory was found in the root of the subjects directory. Yes indicates the directory was found, No otherwise <p> </p>"},{"location":"run_data2bids/03_edf2bids_settings.html","title":"data2bids Settings","text":""},{"location":"run_data2bids/03_edf2bids_settings.html#adjusting-metadata-settings","title":"Adjusting metadata settings","text":"<p>Note</p> <p>You will only need to modify these settings once upon initial installation of the data2bids software</p> <ol> <li> <p>In the data2bids software, select File then Settings.</p> <p> </p> </li> <li> <p>A settings panel will appear with two tabs: Json Metadata and Electrode Info.</p> <ul> <li>Json metadata contains general information about the dataset.<ul> <li>Lab: what is the name of the lab collecting this data</li> <li>Experimenter: list all individuals involved in this dataset</li> <li>Dataset Name: overall name for the dataset.</li> <li>Institution Name/Address: name and address of the institution at which  this dataset was collected</li> </ul> </li> </ul> <p> </p> <ul> <li>Electrode info contains information about the specific electrodes used at the center:<ul> <li>Manufacturer: who produces the electrodes.</li> <li>Type: what type of electrode is it (i.e. depth, scalp etc.)</li> <li>Material: what material are the electrodes made from (i.e. platinum)</li> <li>Diameter: what is the diameter of the electrode (in mm)</li> </ul> </li> </ul> <p> </p> </li> <li> <p>Once you have modified the information click Save and the information will be stored and used for every subsequent dataset processed by data2bids. You will not need to re-define these values, unless they change at your site.</p> </li> </ol>"},{"location":"run_data2bids/03_edf2bids_settings.html#main-window-settings-panel","title":"Main window settings panel","text":"<ol> <li> <p>The settings panel is located at the bottom left of the main window.</p> <p> </p> <ul> <li>De-identify input directory: if this is selected the input EDF/EDF+ files will be de-identified first prior to being copied. If left unchecked, then only the output directory EDF/EDF+ files will be de-identified. Default is unchecked.</li> <li>Offset dates: if selected all dates in the EDF/EDF+ files will be offset by a random number of days (~1000 days). The offset value can be determined but is securely stored.</li> <li>Dry run: this should be selected when running a new conversion. This option will not copy the EDF/EDF+ files to the output directory but will check to ensure the input directory is set-up correctly. Since copying the EDF/EDF+ files is a time-intensive process, this dry-run will be much faster then a full conversion and will notify you if any files are formated incorrectly within the input directory.</li> <li>Compress EDFs (EDFZ): if selected the EDF+ output files will be further compressed using GZIP (with final extension <code>.edfz</code>). For more information, see the documentation from Dr. Shaun Purcell's lab  at Harvard.</li> </ul> </li> </ol> <p> </p>"},{"location":"run_data2bids/04_neuroworks_export.html","title":"Export from NeuroWorks","text":""},{"location":"run_data2bids/04_neuroworks_export.html#creating-an-export-template","title":"Creating an export template","text":"<p>It is a good idea to determine all the headboxes used to collect EEG/iEEG data at your institution. Once known, you will only need to create one template for each headbox.</p> <ol> <li>In NeuroWorks Database, select (highlight) the study patient you want to export (if a patient has used two different headboxes then you will need to make/use a different template for each one).</li> <li>Choose Administration &gt; Export. Alternately, you can right-click and select Export\u2026 from the context menu. The Export Studies dialog opens.</li> <li> <p>Before selecting the Export button, ensure that EDF/EDF+ on the open dialog is selected.  The list of studies will update to include a Template column.</p> <p></p> </li> <li> <p>Right-click on the displayed information for the study. The context menu displays showing the options available.  From the context menu, you can choose one of the following:</p> <p></p> <ul> <li>Edit Template: Edit an existing, selected template</li> <li>Create Template: Create a new template based on the headbox type</li> </ul> <p>Note</p> <p>a new template is not required for each export. You will only need to create one template for every headbox used at your institution. See the sections below on creating and modifying export templates.</p> </li> <li> <p>From the context menu in the Export dialog, select Create Template. The EDF Template Editor dialog displays showing the Channels Tab. </p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#channels-tab","title":"Channels Tab","text":"<ol> <li> <p>Give the template a new name by typing it in the Name box. Ideally create one template for every headbox used at your center. To ensure the templates are not modified or deleted at your center we suggest adding eplink to the template name (i.e. eplink_eeg_128_template or  eplink_quantum_template).</p> </li> <li> <p>The Channels tab dialog allows for the selection of the channels that will be exported in the EDF file, as well as the definition of those channels. </p> <ul> <li>Raw Data (check this box for EpLink): this option exports the study data with no montage associated.</li> <li>Acquisition Montage (ignore): this option exports the study data using the patient\u2019s montage. </li> <li>Montage (ignore): this option exports the study using a compatible montage based on headbox and study type. This can be chosen from the available dropdown menu.</li> </ul> </li> <li> <p>For EpLink select Raw Data.</p> </li> <li> <p>Select the checkbox Add Patient Event Channel to include this channel in the export. You do not need to select Add Trigger Channel.</p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#options-tab","title":"Options Tab","text":"<ol> <li> <p>Select the Options tab to modify the various options associated with exporting the studies to EDF/EDF+.</p> </li> <li> <p>Select the EDF+ radio button to choose the format of the export.</p> </li> <li> <p>Choose the desired File Extension (.EDF) from the dropdown.</p> </li> <li> <p>Do not check the Deidentify Patient Information checkbox. This information will be removed by the conversion software and the patient name is needed in order to remove any potential traces of it from the EDF file, including any annotations. The conversion software will be run before the EEGs are uploaded to Brain-CODE so EEGs will still be de-identified before leaving the site. </p> </li> <li> <p>When the EDF+ option is selected, the Pad Gaps with Zeros checkbox is enabled. Select this checkbox so gaps in the recording will be filled with zeros. This ensures the EDF+ file is continuous. EDF+ supports gaps (disconnects) in the studies, however this makes analysis more difficult as timepoints will be shifted.</p> </li> <li> <p>Select the checkbox next to Invert AC Channels to invert the polarity of the AC channels when the study is exported.</p> </li> <li> <p>We will not select anything in the File Size Limitations box.</p> </li> <li> <p>Click the Save button on the Channels tab prior to clicking OK in order to save the template. Ensure you remember the name of the template for use later.</p> </li> <li> <p>Once saved, you can close the EDF template Editor dialog.</p> <p>Note</p> <p>once you have saved a headbox template, if another patient uses that headbox then the template you created will automatically be selected by NeuroWorks for the subsequent patient.</p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#saving-channel-labels","title":"Saving channel labels","text":"<ol> <li> <p>In NeuroWorks Database, double-click any study for patient you want to export.</p> </li> <li> <p>When the study loads in the viewer, select the first Montage event in the annotations window on the left. This will ensure you are at the point in the recording that the montage was set for the patient.</p> <p></p> </li> <li> <p>Choose Edit &gt; Settings and select the Channel Labels tab. </p> <p></p> </li> <li> <p>Select the From Montage button. This will load the channel labels used for the patient. Select all the labels and save them within a text file called \u201cchannel_labels.txt\u201d.</p> <p></p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#single-edf-export","title":"Single EDF export","text":"<ol> <li> <p>In NeuroWorks Database, select (highlight) the study patient you want to export.</p> </li> <li> <p>Choose Administration &gt; Export. Alternately, you can right-click and select Export\u2026 from the context menu. The Export Studies dialog opens.</p> </li> <li> <p>Before selecting the Export button, ensure that EDF/EDF+ on the open dialog is selected. The list of studies will update to include a Template column.</p> </li> <li> <p>Confirm the template chosen matches the headbox used for that study. If the template is not correct, click on the template name and select the appropriate headbox template.</p> </li> <li> <p>Once you have confirmed the correct headbox template select Export.</p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#batch-edf-export","title":"Batch EDF export","text":"<p>Before running the NeuroWorks EDF batch export, you will need to locate three items.</p> <ol> <li> <p>EDF Export Template: This is the template you saved for the specific headbox.</p> <ul> <li>Find the installation directory for the NeuroWorks software. The directory name will be Neuroworks and it is usually found at <code>C:\\Neuroworks</code> or <code>D:\\Neuroworks</code>. Within this directory select the <code>Settings</code> directory. Finally, find the EDF Export Template you saved previously, it will be the name you chose with the extension .exp.</li> <li>Ensure you are selecting the correct template for the specific patient. Within the NeuroWorks database, search for the patient and make a note of the headbox that was used for that patient (this is found in a column to the far right of the main window)</li> </ul> <p></p> <p>Note</p> <p>The template file needs to remain in the <code>Neuroworks\\Settings</code> directory. If you attempt to run the conversion with a template path outside this directory it won\u2019t run.</p> </li> <li> <p>EDFExport.exe: This is the executable you will use to run the batch export of EDF files.</p> <ul> <li>This executable will be found within the installation directory for the NeuroWorks software. </li> <li>Usually the full path will be located at: <code>C:\\Neuroworks\\EDFExport.exe</code> or <code>D:\\Neuroworks\\EDFExport.exe</code>.</li> </ul> </li> <li> <p>Source Patient Data Directory: If you haven\u2019t exported the subjects data from NeuroWorks yet, you can use the NeuroWorks database storage path to find the subject and avoid having to export from NeuroWorks first.</p> <ul> <li>NeuroWorks stores the raw data for every patient on a Network drive (see figure below). Most often the drive will be <code>Z:\\</code>. You will need to determine where this location is on your system. Right click on the Windows Start Menu and select File Explorer.</li> </ul> <p></p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#create-study-path-text-file","title":"Create study path text file","text":"<ol> <li> <p>Navigate to the NeuroWorks data storage drive. Once in that directory you can now search for the subjects name (Lastname Firstname) in the search box at the top right of the File Explorer window. You can press the red X to stop the search if it seems to be going on forever. The search results up to that point will not be removed if you stop the search.</p> </li> <li> <p>Sort the subjects folders by selecting Date Modified at the top. This will organize the subjects folders from newest to oldest.</p> <p></p> </li> <li> <p>Right click on the computer desktop select New &gt; Text Document. Rename the text document to match the subject you will be exporting.</p> </li> <li> <p>Open the text document. Each line should be the full path the specific study you want to export for the subject. In the NeuroWorks patient directory folder, start at the oldest study folder by scrolling to the bottom. If multiple folders exist on the same day, hover the mouse over each folder to determine the size (iEEG data is typically ~20-25 gb in size).</p> </li> <li> <p>Once you have determined the right directory, open the directory and find the .eeg file (usually at the top). If you right click on the search bar you can copy the directory path and paste it into the text file. Then copy the filename of the .eeg and add that to the text file as well to complete the path. You can also right click on the file select Properties and copy the full path from the window that opens.</p> <p></p> </li> <li> <p>In the text document paste the full path to the .eeg file you just copied. You will then need to provide the full path to where the EDF Export Template is for this subject by adding it to the same line. Following the .eeg path, enter a comma and a space followed by the full path to the template:</p> <p></p> </li> <li> <p>Repeat steps 2-4 for all study dates for the subject.</p> </li> <li> <p>Save the text document and close it.</p> </li> </ol>"},{"location":"run_data2bids/04_neuroworks_export.html#running-batch-export","title":"Running batch export","text":"<ol> <li> <p>Now it is time to run the batch conversion. Click on the Windows start menu and search for Command Prompt. Double click to open a command prompt window.</p> </li> <li> <p>You will now enter the command to perform the conversion, using the information you have previously gathered. </p> </li> <li> <p>Input 1: Type the full path to where you found the EDFExport.exe within quotations:</p> <p></p> </li> <li> <p>Input 2: Press the spacebar and type -f, followed by another space and the path to where the subject text document is located that you created. Put the path within quotations:</p> <p></p> </li> <li> <p>Lastly, you need to specify where you want the exported EDFs to go. Create a new folder on your encrypted hard drive for this export and copy the full path to that directory. </p> </li> <li> <p>Input 3: In the command prompt, enter a space after the path for the text document then enter -o and another space followed by the full path to the output directory. Again, ensure you place the path within quotations:</p> <p></p> <p>In the command prompt window, the function will look like:</p> <p></p> </li> <li> <p>Once you have entered the full command hit the Enter key to begin conversion. For a 25gb file, the conversion will take ~15mins. Return in a few hours to check on the conversion</p> </li> </ol> <p> </p>"},{"location":"run_data2bids/055_imaging_dir_setup.html","title":"Imaging Directory Setup","text":""},{"location":"run_data2bids/055_imaging_dir_setup.html#imaging-data","title":"Imaging Data","text":"<p>data2bids will anonymize imaging DICOM files if they are present within the input directory. The DICOMs should be within a directory named imaging, which is at the root of the subject directory. Within the imaging directory, there should be a sub-directory for all imaging sessions for the subject. The session sub-directories should contain the DICOM files either compressed or uncompressed. The accepted compression formats include: .tar, .tgz, .tar.gz, .tar.bz2, .zip. The DICOM filenames can be anything, you could also place all the DICOM files for all imaging sequences into one directory.</p> <p>The imaging session folders should be in the format <code>EPL31_LHS_001_&lt;ses_num&gt;</code> , where <code>ses_num</code> is the imaging session number for the imaging data. If the subject only has one session, you still need to include the DICOM files within a session sub-directory.</p> <p>For details on the DICOM header tags that are anonymized see the section below.</p>"},{"location":"run_data2bids/055_imaging_dir_setup.html#example","title":"Example","text":""},{"location":"run_data2bids/055_imaging_dir_setup.html#static","title":"Static","text":"<pre><code>input/\n\u251c\u2500\u2500 EPL31_LHS_0001/                           # Individual subject directory\n|\u00a0\u00a0   \u2514\u2500\u2500 imaging/                            # Imaging directory for dicoms\n|      \u00a0\u00a0   \u251c\u2500\u2500 EPL31_LHS_0001_01/            # Imaging sub-directory for each session\n|           |     \u251c\u2500\u2500 T1w_scan/               \n|           |     |       \u251c\u2500\u2500 t1w_file01.dcm\n|           |     |       \u251c\u2500\u2500 t1w_file02.dcm  # optional DICOM directories for each sequence, can be given any name\n|           |     |       \u2514\u2500\u2500 t1w_file03.dcm\n|           |     |\n|           |     \u251c\u2500\u2500 T2w_scan/\n|           |     |       \u251c\u2500\u2500 t2w_file01.dcm\n|           |     |       \u251c\u2500\u2500 t2w_file02.dcm\n|           |     |       \u2514\u2500\u2500 t2w_file03.dcm\n|           |     |\n|           |     \u2514\u2500\u2500 dwi_scan/\n|           |           \u2514\u2500\u2500 dwi_scan.tar.gz   # the DICOM files can be stored in a compressed format (i.e. tar.gz)\n|           |\n|           \u2514\u2500\u2500 EPL31_LHS_0001_02/\n|                 \u251c\u2500\u2500 t1w_scan.tar.gz\n|                 \u2514\u2500\u2500 dwi_scan.tar.gz\n|\n\u2514\u2500\u2500 EPL31_LHS_0002/                           \n \u00a0\u00a0   \u2514\u2500\u2500 imaging/                            \n       \u00a0\u00a0   \u2514\u2500\u2500 EPL31_LHS_0002_01/            \n                 \u251c\u2500\u2500 t1w_scan_01.dcm\n                 \u251c\u2500\u2500 t1w_scan_02.dcm\n                 \u251c\u2500\u2500 t1w_scan_03.dcm          # you can combine all the DICOM files into one directory\n                 \u251c\u2500\u2500 dwi_scan_01.dcm\n                 \u251c\u2500\u2500 dwi_scan_02.dcm\n                 \u2514\u2500\u2500 dwi_scan_03.dcm\n</code></pre>"},{"location":"run_data2bids/055_imaging_dir_setup.html#interactive","title":"Interactive","text":""},{"location":"run_data2bids/055_imaging_dir_setup.html#anonymization","title":"Anonymization","text":"<p>Certain DICOM viewers and analysis tools require specific DICOM header tags to be present. Complete removal of these tags may render the DICOMS unreadable by these tools. Instead, the DICOM header tags that are deemed an identifier are overwritten by random data. The tool used to perform this action is dicognito.</p> Anonymized DICOM tags Attribute Description AccessionNumber (0008,0050) A RIS generated number that identifies the order for the Study. FillerOrderNumberImagingServiceRequest (0040,2017) The order number assigned to the Imaging Service Request by the party filling the order. InstitutionName (0008,0080) Institution where the equipment that produced the Composite Instances is located. InstitutionAddress (0008,0081) Mailing address of the institution where the equipment that produced the Composite Instances is located. InstitutionalDepartmentName (0008,1040) Department in the institution where the equipment that produced the Composite Instances is located. OtherPatientNames (0010,1001) Other names used to identify the Patient. PatientID (0010,0020) Primary hospital identification number or code for the patient. PerformedProcedureStepID (0040,0253) User or equipment generated identifier of that part of a Procedure that has been carried out within this step. PlacerOrderNumberImagingServiceRequest (0040,2016) The order number assigned to the Imaging Service Request by the party placing the order. RequestedProcedureID (0040,1001) Identifier that identifies the Requested Procedure in the Imaging Service Request. ScheduledProcedureStepID (0040,0009) Identifier that identifies the Scheduled Procedure Step. StationName (0008,1010) User defined name identifying the machine that produced the Composite Instances. StudyID (0020,0010) User or equipment generated Study identifier. Removed DICOM tags Attribute/Tag Description CountryOfResidence (0010,2150) Country in which patient currently resides. Occupation (0010,2180) Occupation of the Patient. PatientAddress (0010,1040) Legal address of the named patient. RegionOfResidence (0010,2152) Region within patient's country of residence. <p> </p>"},{"location":"run_data2bids/05_input_dir_setup.html","title":"Input Directory Setup","text":"<p>This section outlines how the data should be organized prior to running the data2bids software. The data files should be in EDF/EDF+ format following the specifications provided by the EDF format developers. </p> <p>Setup a working directory is a recommended way to organize your working directory of data (this is optional but highly recommended).</p> <p>Note</p> <p>At this moment the names of the EDF/EDF+ files are not yet BIDS compliant, but they do contain some metadata in the filename that will be used later.</p>"},{"location":"run_data2bids/05_input_dir_setup.html#setup-a-working-directory","title":"Setup a working directory","text":"<p>It is recommended that you establish a working directory to ensure your data remains organized. The optimal setup would be one with the following five directories:</p> <ul> <li>unorganized: this directory holds unorganized subject data ready to be organized for data2bids</li> <li>organized: this directory holds organized subject data ready to be organized for data2bids (according to either option below)</li> <li>input: this directory holds subject data ready to be converted with data2bids</li> <li>output: this directory holds the output converted data from data2bids</li> <li>complete: this directory holds the fully converted data from the output directory (which needs to be empty every time a new conversion is occurring)</li> </ul> <p>Warning</p> <p>When beginning a conversion with data2bids ensure the output directory is empty and the input directory only contains the subject folders you wish to convert.</p>"},{"location":"run_data2bids/05_input_dir_setup.html#static-example","title":"Static example","text":"<pre><code>working_dir/\n\u251c\u2500\u2500 unorganized/\n\u251c\u2500\u2500 organized/\n\u251c\u2500\u2500 input/\n\u251c\u2500\u2500 output/\n\u2514\u2500\u2500 complete/\n</code></pre>"},{"location":"run_data2bids/05_input_dir_setup.html#interactive-example","title":"Interactive example","text":""},{"location":"run_data2bids/05_input_dir_setup.html#input-directory","title":"Input directory","text":"<p>If you do not require a specific naming convention for visits and sessions then Option 01: Do not specify visit/session number should be followed. In this option, the visit and session number are not supplied to the data2bids software and instead are automatically determined based on the date/time of the EDF/EDF+ acquisition.</p> <p>For the EpLink study, you should follow Option 02: Specify visit/session number.</p>"},{"location":"run_data2bids/05_input_dir_setup.html#option-01-do-not-specify-visitsession-number","title":"Option 01: Do not specify visit/session number","text":"<p>If you do not need to specify the visit or session number for each EDF file for the subjects, then this option will assign session numbers based on the Date timestamp within the EDF files. So the earliest EDF file will be given ses-001 while the latest EDF file will be given ses-### (### will be equal to the number of EDF files for that subject).</p> <p>Input directory</p> <p>The input directory (<code>input</code>) should contain a sub-directory for each of the subjects you want to have converted (i.e. <code>input\\sub-001</code>, <code>input\\sub-002</code> etc.). Within the data2bids software you select <code>input</code> as the input directory and not the individual subject directories</p> <p>Definition of terms</p> <p>for a complete list of terms see the definitions page</p>"},{"location":"run_data2bids/05_input_dir_setup.html#static-example_1","title":"Static example","text":"<pre><code>input/\n\u251c\u2500\u2500 &lt;sub_num&gt;/                                          # Individual subject directory\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 X~X_432a35cf-adg25-462-24aa-325db4e5e2d3.edf    # Individual EDF files\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 X~Xe_7d22151a-ac455-3adc312b-426aae3251ac.edf\n\u2502\n\u2514\u2500\u2500 &lt;sub_num&gt;/                                          # Individual subject directory\n\u00a0\u00a0  \u251c\u2500\u2500 X_ X_35a1ed7a-7764-4cb0-8571-51026e3dbef4.edf   # Individual EDF files\n\u00a0\u00a0  \u2514\u2500\u2500 X_X_e515c5ac-6301-4acd-8a69-fb208d5fd097.edf\n</code></pre>"},{"location":"run_data2bids/05_input_dir_setup.html#interactive-example_1","title":"Interactive example","text":""},{"location":"run_data2bids/05_input_dir_setup.html#option-02-specify-visitsession-number","title":"Option 02: Specify visit/session number","text":"<p>In some instances you may want to manually assign the specific visit or session numbers for the EDF files. In this scenario you would need to place each EDF file into a directory with the following naming scheme:</p> <pre><code>&lt;sub_num&gt;_&lt;visit_num&gt;_&lt;ses_num&gt;_&lt;type&gt;_&lt;task&gt;_[RET]\n</code></pre> <p>Definition of terms</p> <p>for a complete list of terms see the definitions page</p> <pre><code>sub-003_02_SE01_IEEG_FULL_RET\n</code></pre> <p>A folder with the above naming scheme would indicate this is subject 3's second visit and first session. The data collected was a full IEEG recording that was retrospective (recorded prior to the subject consent).</p> <p>Input directory</p> <p>The input directory (<code>input</code>) should contain a sub-directory for each of the subjects you want to have converted (i.e. <code>input\\sub-001</code>, <code>input\\sub-002</code> etc.). Within the data2bids software you select <code>input</code> as the input directory and not the individual subject directories</p> <p>Each day of recording should be in a separate folder within the subject directory:</p>"},{"location":"run_data2bids/05_input_dir_setup.html#static-example_2","title":"Static example","text":"<pre><code>input/\n\u251c\u2500\u2500 &lt;sub_num&gt;/                                                # Individual subject directory\n\u2502\u00a0\u00a0 \u2502\n\u2502   \u251c\u2500\u2500 &lt;sub_num&gt;_&lt;visit_num&gt;_&lt;ses_num&gt;_&lt;type&gt;_&lt;task&gt;_[RET]/  # Specify visit, session, type, and task\n\u2502\u00a0\u00a0 \u2502   \u2502\n\u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 X~X_432a35cf-adg25-462-24aa-325db4e5e2d3.edf      # Individual EDF files\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 X~Xe_7d22151a-ac455-3adc312b-426aae3251ac.edf     # Individual EDF files\n\u2502\u00a0\u00a0 \u2502\n\u2502   \u2514\u2500\u2500 &lt;sub_num&gt;_&lt;visit_num&gt;_&lt;ses_num&gt;_&lt;type&gt;_&lt;task&gt;_[RET]/  # Specify visit, session, type, and task\n\u2502\u00a0\u00a0     \u2502     \n\u2502\u00a0\u00a0     \u2514\u2500\u2500 X~X_432a35cf-adg25-462-24aa-325db4e5e2d3.edf      # Individual EDF files\n\u2502\n\u2514\u2500\u2500 &lt;sub_num&gt;/                                                # Individual subject directory\n    \u2502\n    \u2514\u2500\u2500 &lt;sub_num&gt;_&lt;visit_num&gt;_&lt;ses_num&gt;_&lt;type&gt;_&lt;task&gt;_[RET]/  # Specify visit, session, type, and task\n\u00a0\u00a0      \u2502\n\u00a0\u00a0      \u251c\u2500\u2500 X~X_432a35cf-adg25-462-24aa-325db4e5e2d3.edf      # Individual EDF files\n\u00a0\u00a0      \u2514\u2500\u2500 LastName~ FirstName_7d22151a-ac455-3adc312b-426aae3251ac.edf     # You can include the subject first/last name to be used when de-identifying the data\n</code></pre>"},{"location":"run_data2bids/05_input_dir_setup.html#interactive-example_2","title":"Interactive example","text":""},{"location":"run_data2bids/05_input_dir_setup.html#channel-labels","title":"Channel labels","text":"<p>For recordings where patient specific channel labels are defined, a channel labels text file should be created that dictates how the labels should appear within the EDF file. For instance, EEG recordings commonly make use of the 10-20 setup, which means the channel labels do not change between patients. However, in iEEG recordings, channels labels are unique to the patient depending on where the depth electrodes were implanted. To ensure the EDF file has the correct channel labels, you should create a text file called \"*_channel_labels.txt\", where * indicates any string can be placed there but the file name needs to end with channel_labels.txt (i.e. sub-001_channel_labels.txt, EPL31_LHS_0001_channel_labels.txt).</p> <p>When creating the channel labels file you do not need to include default NeuroWorks channels, such as:</p> <ul> <li>Patient Event</li> <li>TRIG</li> <li>OSAT</li> <li>PR</li> <li>Pleth</li> <li>EDF Annotations</li> </ul> <p>You only need to provide channels with unique names for the specific patient, for instance:</p> <ul> <li>LAHc1</li> <li>RAm1</li> </ul> <p>The implanted depth electrodes each have several contacts on them to record from. So the contacts on the electrode are numbered, such as:</p> <ul> <li>10 contact electrode LAHc: LAHc1, LAHc2, LAHc3, LAHc4, LAHc5, LAHc6, LAHc7, LAHc8, LAHc9, LAHc10 </li> </ul> <p>When creating the channel labels file, it is easiest to use Excel or Libreoffice. The first column should contain C1 to Cn, where n is the total number of iEEG channels used in the recording. Next to each channel number, place the corresponding electrode contacts name.</p> Example _channel_labels.txt file C1 LOFr1 C2 LOFr2 C3 LOFr3 C4 LOFr4 C5 LOFr5 C6 LOFr6 C7 LOFr7 C8 LOFr8 C9 LOFr9 C10 LOFr10 C11 LCg1 C12 LCg2 C13 LCg3 C14 LCg4 C15 LCg5 C16 LCg6 C17 LCg7 C18 LCg8 C19 LCg9 C20 LCg10 C21 LAm1 C22 LAm2 C23 LAm3 C24 LAm6 C25 LAm7 C26 LAm8 C27 LAm9 C28 LAm10 C29 LAHc1 C30 LAHc2 C31 LAHc3 C32 LAHc6 C33 LAHc7 C34 LAHc8 C35 LAHc9 C36 LAHc10 <p> </p>"},{"location":"run_data2bids/06_check_edf_type.html","title":"Check EDF Type","text":"<p>Detailed EDF format description</p> <p>for a detailed explanation of the EDF format see the description page</p>"},{"location":"run_data2bids/06_check_edf_type.html#edf-type-overview","title":"EDF Type Overview","text":"<p>Only EDF+ files can be stored in either a continuous (EDF+C) or discontinuous (EDF+D) format, while EDF files can only be continuous. A discontinuity within the EDF+ file would occur when the recording is stopped and subsequently started again, resulting in a lapse in recording time. There are two ways to account for the missing data during the non-recording period:</p> <ul> <li>Continuous: to keep the timeline in the file continuous, the data record during the non-recording time can be filled with zeros. This would maintain the timeline within the file.</li> <li>Discontinuous: ignore the time the recording stopped and \"Glue\" the different recording sessions together. This creates a jump in the timeline of the EDF+ file.</li> </ul> <p>For most applications, the EDF+ file will need to be in <code>EDF+C</code> format. The majority of softwares and analysis tools require this.</p>"},{"location":"run_data2bids/06_check_edf_type.html#convert-edf-type","title":"Convert EDF Type","text":"<p>You need to ensure all EDF+ files are in continuous format (EDF+C). This is easy to check within data2bids. </p> <ol> <li>Ensure your input directory has been organized prior to opening within data2bids.</li> <li>Within data2bids select the input directory and check the <code>EDF Type</code> column. You should flag any file that is in <code>EDF+D</code> format.</li> <li> <p>Once you have identified the files that are in <code>EDF+D</code> format, open EDFBrowser, select Tools at the top and Convert EDF+D to EDF+C.</p> <p></p> </li> <li> <p>A dialog box will open allowing you to select one of the identified files that is in <code>EDF+D</code> format, select one file.</p> </li> <li>Once conversion is complete you will notice the original file remains but now there are several smaller files with a 4 digit suffix accounting for the number of times the recording was stopped/started.</li> </ol> <p> </p>"},{"location":"run_data2bids/07_run_conversion.html","title":"Run Conversion","text":""},{"location":"run_data2bids/07_run_conversion.html#input-directory-selection","title":"Input directory selection","text":"<p>The input directory selected here should be organized according to the first section in this documentation. Prior to loading the data, make sure all the settings in the settings panel have been configured to your specification (found at the bottom left of the main window).</p> <ol> <li> <p>In the software, select Input Directory and choose the directory that contains the data to be converted (select the main/root directory that contains all subject directories). Click Select Folder in the window and the data will load into the Input Directory window.</p> <p></p> </li> <li> <p>You will now be able to review the information that was detected about the input files. Each subject is expandable by clicking the box beside the subject name. The columns displayed are:</p> </li> </ol> <p>Definition of columns</p> <p>for a complete list of column explanations see the definitions page</p>"},{"location":"run_data2bids/07_run_conversion.html#output-directory-selection","title":"Output directory selection","text":"<ol> <li> <p>Once you have confirmed the input data is correct, click Output Directory and select the directory you want the BIDS dataset to appear. The Output Directory window will now present the final output file information (prior to conversion). This is the final check to ensure that any changes have been updated.</p> <p></p> <p>Note</p> <p>EDF/EDF+ files in the Input Directory will be COPIED to the new location and will be renamed to be BIDS compliant. Thus, you will have two copies of the EDF/EDF+ files. This is a safety measure in case an error occurs in the conversion, the source data will remain intact.</p> </li> <li> <p>If you are converting data for a participant that already has recordings in the output folder, the check boxes for those recordings will appear checked in the Output Directory window.</p> </li> </ol>"},{"location":"run_data2bids/07_run_conversion.html#dry-run-prior-to-conversion","title":"Dry-run prior to conversion","text":"<p>It is recommended that you dry-run the conversion. This ensures the input directory is set-up correctly and that the EDF files are properly formatted. During annotation extract, the EDF file format is checked using EDFBrowser libraries. Since copying the EDF file to the output directory is the most time intensive aspect, you are able to run annotation extraction (with file checking) as a separate dry-run.</p> <p>If an error is found within an EDF file, you will see a message similar to this:</p> <p></p> <p>You should scroll upwards to find the last session that was being converted, prior to the error, and remove it from the input directory:</p> <p></p>"},{"location":"run_data2bids/07_run_conversion.html#convert-to-bids","title":"Convert to BIDs","text":"<ol> <li> <p>Once you have confirmed the Output Directory file information is correct press the green Convert button.</p> </li> <li> <p>During the conversion process you can cancel the conversion at any time by pressing the Cancel button. However, if you cancel the conversion you will need to delete the contents of the output directory and start over.</p> </li> <li> <p>You will receive updates in the Conversion Status window. The final notice, once the conversion is complete, will show Your data has been BIDsified!. </p> <p></p> </li> </ol>"},{"location":"run_data2bids/07_run_conversion.html#convert-to-spred-eplink","title":"Convert to SPReD (EpLink)","text":"<p>Note</p> <p>files will be moved from the BIDS structure to SPReD structure (the BIDs format will be destroyed)</p> <p>The format required to upload the Brain-CODE is different from BIDS. This conversion step will provide a SPReD compliant format output.</p> <ol> <li> <p>Following successful conversion to BIDS, a new button in the main window will become active named SPReD.</p> </li> <li> <p>Press the SPReD button and wait for the conversion to complete.</p> <p></p> </li> </ol>"},{"location":"run_data2bids/07_run_conversion.html#imaging-anonymization","title":"Imaging Anonymization","text":"<p>If an <code>imaging</code> directory was supplied in the input directory then the blue imaging button will be active. </p> <ol> <li> <p>Following conversion to BIDS/SPReD, press the blue button named Imaging.</p> </li> <li> <p>Wait for the conversion to complete.</p> <p></p> </li> </ol> <p> </p>"},{"location":"run_data2bids/08_output_structure.html","title":"BIDS directory structure","text":"<p>The output directory will look like the following (each subject having their own directory):</p> <p></p> <ul> <li>code: this directory will contain the code used to convert the EDF/EDF+ data for each EDF/EDF+ file for the subjects.</li> <li>dataset_description.json: this file will contain the Json Metadata previously defined in the Settings menu. This is overall information about the dataset</li> <li>participants.tsv: this file contains a list of all the subjects in the dataset and their general demographics (i.e. age, sex etc.). This file can also be used to store additional subject information that is not variable over the different visits and sessions. </li> </ul>"},{"location":"run_data2bids/08_output_structure.html#electrodes-vs-channels","title":"Electrodes vs. channels","text":"<p>It is important to understand the difference between the terms <code>electrode</code> and <code>channel</code>. An iEEG electrode is placed on or in the brain, whereas a channel is the combination of the analog differential amplifier and analog-to-digital converter that result in a potential (voltage) difference that is stored in the EEG/iEEG dataset.</p> <ul> <li>Electrode: a single point of contact between the acquisition system and the recording site. Multiple electrodes can be organized as arrays, grids, leads, strips, probes, shafts, caps (for EEG) etc.</li> <li>Channel: a single analog-to-digital converter in the recording system that regularly samples the value of a transducer, which results in the signal being represented as a time series in the digitized data. This can be connected to two electrodes (to measure the potential difference between them), a magnetic field or magnetic gradient sensor, temperature sensor, accelerometer etc.</li> </ul>"},{"location":"run_data2bids/08_output_structure.html#subject-directory","title":"Subject directory","text":"<p>Within each subject directory there will be a different session sub-directory for each day of recording.</p> <p></p>"},{"location":"run_data2bids/08_output_structure.html#_scanstsv","title":"*_scans.tsv","text":"<p>The <code>*_scans.tsv</code> file contains general information about each EDF file for the subject (i.e. filename, recording duration, EDF+ type etc.).</p> <p> Example content of the *_scans.tsv file. <p></p> <ul> <li>filename: relative filename for each EDF/EDF+ file.</li> <li>acq_time: the date and time the recording was started in the format YYYY-MM-DDTHH:MM:SS (note: the <code>T</code> is used to separate the date from time)</li> <li>duration: the total duration of the EDF/EDF+ file in decimal hours</li> <li>edf_type: indicates the EDF type for the file, either continuous (EDF+C) or discontinuous (EDF+D) </li> </ul>"},{"location":"run_data2bids/08_output_structure.html#session-directory","title":"Session directory","text":"<p>Within each session sub-directory there will be a modality sub-directory (either eeg/ieeg). Within the modality sub-directory there will be five files, containing different information associated with the specific EDF/EDF+ file.</p> <p></p>"},{"location":"run_data2bids/08_output_structure.html#_electrodestsv","title":"*_electrodes.tsv","text":"<p>The <code>*_electrodes.tsv</code> file contains information associated with the electrodes used to collect the data.</p> <p> Example content of the *_electrodes.tsv file. <p></p> <ul> <li>name: label given to the specific channel during the recording.</li> <li>x,y,z: the coordinates in MRI space for the specific electrode contact.</li> <li>size: the diameter of the recording electrode in millimeters</li> <li>type: the electrode type (i.e. depth, scalp etc.)</li> <li>material: the electrode material.</li> <li>manufacturer: the manufacturer of the electrode.</li> </ul>"},{"location":"run_data2bids/08_output_structure.html#_channelstsv","title":"*_channels.tsv","text":"<p>The <code>*_channels.tsv</code> file contains information about each channel that was used in the recording.</p> <p> Example content of the *_channels.tsv file. <p></p> <ul> <li>name: label of the specific channel.</li> <li>type: type of channel (i.e. SEEG,EEG, DBS, EOG, ECG etc.)</li> <li>units: physical unit of the value represented in this channel (i.e. <code>V</code> for Volt)</li> <li>low_cutoff: frequency used for the low pass filter applied to the channel in Hz (note: if no low pass filter was applied, <code>n/a</code> is used).</li> <li>high_cutoff: frequency used for the high pass filter applied to the channel in Hz (note: if no high pass filter was applied, <code>n/a</code> is used).</li> <li>sampling_frequency: sampling rate of the channel in Hz.</li> <li>notch: frequency used for the notch filter applied to the channel in Hz (note: if no notch filter was applied, <code>n/a</code> is used).</li> <li>reference: label for the reference (i.e. 'mastoid', 'ElectrodeName01', 'intracranial' etc.). If the channel is not known then <code>n/a</code> is used.</li> <li>group: which group of channels (grid/strip/seeg/depth) this channel belongs to. This is relevant because one group has one cable-bundle and noise can be shared.</li> </ul>"},{"location":"run_data2bids/08_output_structure.html#_annotationstsv","title":"*_annotations.tsv","text":"<p>The <code>*_annotations.tsv</code> file contains all annotations present in the EDF+ file, identifiers have been scrubbed.</p> <p> Example content of the *_annotations.tsv file. <p></p> <ul> <li>onset: the time the event occurred, relative to the time the recording began.</li> <li>duration: the duration of the marked event (-1 indicates no duration, which is default for all events).</li> <li>time_abs: the absolute time for the event (real world time).</li> <li>time_rel: the relative time for the event (time elapsed since the beginning of the recording).</li> <li>event: the event marker text.</li> </ul>"},{"location":"run_data2bids/08_output_structure.html#_eegjson-or-_ieegjson","title":"*_eeg.json or *_ieeg.json","text":"<p>The <code>*_eeg.json</code>/<code>*_ieeg.json</code> file contains metadata information about the EDF/EDF+ file.</p> <p> Example content of the *_eeg.json or *_ieeg.json file. <p></p> <ul> <li>TaskName: name of the task, no two tasks should have the same name (i.e. <code>full</code> for a full 24hr recording, <code>clip</code> if the data has been clipped by the neurologist etc.)</li> <li>InstitutionName: name of the institution in charge of the equipment that produced the composite instances.</li> <li>InstitutionAddress: address of the institution in charge of the equipment that produced the composite instances.</li> <li>Manufacturer: manufacturer of the amplifier system.</li> <li>ManufacturersModelName: manufacturer's designation of the EEG/iEEG amplifier model.</li> <li>SamplingFrequency: sampling frequency (in Hz) of all the EEG/iEEG channels in the recording</li> <li>HardwareFilters: the frequencies of the temporal hardware filters applied, if none exist then <code>n/a</code> is used.</li> <li>SoftwareFilters: the frequencies of the temporal software filters applied, if none exist then <code>n/a</code> is used.</li> <li>*ChannelCount: number of the respective channels included in the recording (i.e. EEG, EOG, ECG, SEEG etc.)</li> <li>PowerLineFrequency: frequency (in Hz) of the power grid where the EEG/iEEG recording was done (for example, 50 or 60).</li> <li>RecordingDuration: length of the recording in decimal hours.</li> <li>RecordingType: defines whether the recording is <code>continuous</code>, <code>discontinuous</code> or <code>epoched</code>, where <code>epoched</code> is limited to time windows about events of interest.</li> <li>SubjectArtefactDescription: freeform description of the observed subject artifact and its possible cause (i.e. \"door open\", \"nurse walked into room at 2 min\", \"seizure at 10 min\").</li> <li>iEEGPlacementScheme: freeform description of the placement of the EEG/iEEG electrodes.</li> <li>iEEGElectrodeGroups: field to describe the way electrodes are grouped into strips, grids or depth probes.</li> <li>iEEGReference: general description of the reference scheme used and (when applicable) of location of the reference electrode in the raw recordings (i.e. \"left mastoid\", \"bipolar\").</li> <li>ElectrodeManufacturer: manufacturer for the electrodes used during the recording (i.e. AD-TECH, DIXI)</li> <li>ElectricalStimulationParameters: free form description of stimulation parameters, such as frequency or shape.</li> </ul>"},{"location":"run_data2bids/08_output_structure.html#_eegedf-or-_ieegedf","title":"*_eeg.edf or *_ieeg.edf","text":"<p>The <code>*_eeg.edf</code>/<code>*_ieeg.edf</code> contains the raw electrophysiology data.</p>"},{"location":"run_data2bids/08_output_structure.html#example-structure","title":"Example Structure","text":""},{"location":"run_data2bids/08_output_structure.html#interactive","title":"Interactive","text":""},{"location":"run_data2bids/08_output_structure.html#spred-directory-structure","title":"SPReD directory structure","text":"<ol> <li> <p>When the SPReD conversion is completed a new sub-directory will be created in the output directory. All unused BIDS files will be transferred to the bids_old sub-directory, while all the SPReD files will be moved to the SPReD sub-directory.</p> <p></p> </li> <li> <p>Within each sub-directory of the .zip folders the same files from the BIDS output will be found:</p> <p></p> </li> <li> <p>You will be uploading the .zip directories to Brain-CODE.</p> </li> </ol> <p> </p>"},{"location":"run_data2bids/09_spred_upload.html","title":"SPReD Upload [EpLink]","text":""},{"location":"run_data2bids/09_spred_upload.html#upload-data-to-spred","title":"Upload data to SPReD","text":"<ol> <li> <p>Login to SPReD and navigate to the EPL31 project for your site.</p> <p></p> </li> <li> <p>Create a new subject by pulling down the New menu near the top of the screen and selecting Subject.</p> <p></p> </li> <li> <p>This will take you to the new subject page. It is recommended that you enter the participant\u2019s age and gender however these are optional. The only required field is the Subject\u2019s ID.</p> <p></p> </li> <li> <p>Press Submit at the bottom of the page when done.</p> </li> <li> <p>You are now on the main subject page. From here click Add Experiment on the right.</p> <p></p> </li> <li> <p>On this page, select EEG Session.</p> <p></p> </li> <li> <p>Enter the participant\u2019s session name and visit ID, these should be the same as the zip file name. It is also recommended that you enter the date of the recording, but it is not required. In the list of scans, click the scissors icon to delete all but the first row. In the remaining row enter 1 for Scan number and EEG for type. You may also optionally add a note about the scan.</p> <p> \u2b07 </p> </li> <li> <p>Press Submit at the bottom of the page when done.</p> </li> <li> <p>You are now on the main session page. From here click on Manage Files on the right.</p> <p></p> </li> <li> <p>In the window that pops up, click on Add Folder. In the other window that pops up, for Level select scans, for Item select 1 and for Folder enter EEG. Once done click Create.</p> <p></p> </li> <li> <p>Now click on Upload Files. In the window that pops up select the folder we just created, for Level select scans, for Item select 1 and for Folder select EEG. Now click on Browse\u2026 and navigate to the zip file corresponding with the session you wish to upload.</p> <p></p> </li> <li> <p>Once the file has been selected, click on Upload.</p> <p></p> </li> <li> <p>There will be another box that pops up asking you would like to extract the contents of the archive, click Cancel.</p> <p></p> </li> <li> <p>You are done! If you have more EEG sessions to upload for this participant, you can go back to the main subject page by clicking on the navigation links at the top. You can then repeat from step 5 and on.</p> <p></p> </li> </ol> <p> </p>"}]}