
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Greydon Gilmore">
      
      
      
        <link rel="prev" href="other_software.html">
      
      
      <link rel="icon" href="img/edf2bids_icon.svg">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.17">
    
    
      
        <title>Open Datasets - data2bids v3.1</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="red">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#open-datasets-in-electrophysiology" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="data2bids v3.1" class="md-header__button md-logo" aria-label="data2bids v3.1" data-md-component="logo">
      
  <img src="img/edf2bids_white_icon.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            data2bids v3.1
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Open Datasets
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/greydongilmore/data2bids-site" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="data2bids v3.1" class="md-nav__button md-logo" aria-label="data2bids v3.1" data-md-component="logo">
      
  <img src="img/edf2bids_white_icon.svg" alt="logo">

    </a>
    data2bids v3.1
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/greydongilmore/data2bids-site" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="installation.html" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Run data2bids
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Run data2bids
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/01_overview.html" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/02_definitions.html" class="md-nav__link">
        Definitions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/03_edf2bids_settings.html" class="md-nav__link">
        data2bids Settings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/04_neuroworks_export.html" class="md-nav__link">
        Export from NeuroWorks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/05_input_dir_setup.html" class="md-nav__link">
        Input Directory Setup
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/055_imaging_dir_setup.html" class="md-nav__link">
        Imaging Directory Setup
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/06_check_edf_type.html" class="md-nav__link">
        Check EDF Type
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/07_run_conversion.html" class="md-nav__link">
        Run Conversion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/08_output_structure.html" class="md-nav__link">
        Output Directory Structure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="run_data2bids/09_spred_upload.html" class="md-nav__link">
        SPReD Upload [EpLink]
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          ieegProc
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          ieegProc
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ieegProc/01_overview.html" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ieegProc/05_output.html" class="md-nav__link">
        Output
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="manuals.html" class="md-nav__link">
        Product Manuals
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="other_software.html" class="md-nav__link">
        Other Software
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Open Datasets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="open_datasets.html" class="md-nav__link md-nav__link--active">
        Open Datasets
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-formats" class="md-nav__link">
    Data Formats
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#repositories" class="md-nav__link">
    Repositories
  </a>
  
    <nav class="md-nav" aria-label="Repositories">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neuroscience-specific-data-repositories" class="md-nav__link">
    Neuroscience Specific Data Repositories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-purpose-data-repositories" class="md-nav__link">
    General Purpose Data Repositories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-journals" class="md-nav__link">
    Data Journals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-search-engines" class="md-nav__link">
    Data Search Engines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#eeg-data" class="md-nav__link">
    EEG Data
  </a>
  
    <nav class="md-nav" aria-label="EEG Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#childmind-institute" class="md-nav__link">
    ChildMind Institute
  </a>
  
    <nav class="md-nav" aria-label="ChildMind Institute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hbn-healthy-brain-networks" class="md-nav__link">
    HBN - Healthy Brain Networks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mipdb-multimodal-resource-for-studying-information-processing-in-the-developing-brain" class="md-nav__link">
    MIPDB - Multimodal Resource for Studying Information Processing in the Developing Brain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#physionet" class="md-nav__link">
    Physionet
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict-patient-repository-for-eeg-data-computational-tools" class="md-nav__link">
    PREDICT - Patient Repository for EEG Data + Computational Tools
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tuh-temple-university-hospital-corpus" class="md-nav__link">
    TUH - Temple University Hospital Corpus
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eegbase" class="md-nav__link">
    EEGbase
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nitrc-neuroimaging-tools-resource-collaboratory" class="md-nav__link">
    NITRC - Neuroimaging Tools &amp; Resource Collaboratory
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#erp-core" class="md-nav__link">
    ERP-CORE
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnci-horizon-2020" class="md-nav__link">
    BNCI Horizon 2020
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mass-montreal-archive-of-sleep-studies" class="md-nav__link">
    MASS - Montreal Archive of Sleep Studies
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nsrr-national-sleep-research-resource" class="md-nav__link">
    NSRR - National Sleep Research Resource
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-cuban-human-brain-mapping-project" class="md-nav__link">
    The Cuban Human Brain Mapping Project
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemon-leipzig-study-for-mind-body-emotion-interactions" class="md-nav__link">
    LEMON - Leipzig Study for Mind-Body-Emotion Interactions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#peers-the-penn-electrophysiology-of-encoding-and-retrieval-study" class="md-nav__link">
    PEERS - The PENN Electrophysiology of Encoding and Retrieval Study
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lab-specific-data-collections" class="md-nav__link">
    Lab-Specific Data Collections
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-research-tasks-research-systems" class="md-nav__link">
    Individual EEG Datasets - Research Tasks (Research Systems)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-research-tasks-consumer-systems" class="md-nav__link">
    Individual EEG Datasets - Research Tasks (Consumer Systems)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-clinical-recordings" class="md-nav__link">
    Individual EEG Datasets - Clinical Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-lists-of-eeg-data" class="md-nav__link">
    Other lists of EEG Data
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#meg-data" class="md-nav__link">
    MEG Data
  </a>
  
    <nav class="md-nav" aria-label="MEG Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#omega-open-meg-archive" class="md-nav__link">
    OMEGA - Open MEG Archive
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hcp-human-connectome-project" class="md-nav__link">
    HCP - Human Connectome Project
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camcan-cambridge-center-for-ageing-neuroscience" class="md-nav__link">
    CAMCAN - Cambridge Center for Ageing Neuroscience
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-meg-datasets" class="md-nav__link">
    Individual MEG Datasets
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#human-intracranial-data" class="md-nav__link">
    Human Intracranial Data
  </a>
  
    <nav class="md-nav" aria-label="Human Intracranial Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mni-open-ieeg-atlas" class="md-nav__link">
    MNI Open iEEG Atlas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ieegorg" class="md-nav__link">
    iEEG.org
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#university-of-pennsylvania-computational-memory-lab" class="md-nav__link">
    University of Pennsylvania Computational Memory Lab
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kai-millers-collection-of-ecog-data" class="md-nav__link">
    Kai Miller's Collection of ECoG Data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-ieeg-datasets-research-recordings" class="md-nav__link">
    Individual iEEG Datasets - Research Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-ieeg-datasets-clinical-recordings" class="md-nav__link">
    Individual iEEG Datasets - Clinical Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#human-single-unit-data" class="md-nav__link">
    Human Single Unit Data
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#animal-lfp-data" class="md-nav__link">
    Animal LFP Data
  </a>
  
    <nav class="md-nav" aria-label="Animal LFP Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neurotycho" class="md-nav__link">
    NeuroTycho
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collaborative-research-in-computational-neuroscience-crcns" class="md-nav__link">
    Collaborative Research in Computational Neuroscience (CRCNS)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lab-specific-data-collections_1" class="md-nav__link">
    Lab-Specific Data Collections
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-datasets" class="md-nav__link">
    Individual Datasets
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavioral-data" class="md-nav__link">
    Behavioral Data
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-formats" class="md-nav__link">
    Data Formats
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#repositories" class="md-nav__link">
    Repositories
  </a>
  
    <nav class="md-nav" aria-label="Repositories">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neuroscience-specific-data-repositories" class="md-nav__link">
    Neuroscience Specific Data Repositories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-purpose-data-repositories" class="md-nav__link">
    General Purpose Data Repositories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-journals" class="md-nav__link">
    Data Journals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-search-engines" class="md-nav__link">
    Data Search Engines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#eeg-data" class="md-nav__link">
    EEG Data
  </a>
  
    <nav class="md-nav" aria-label="EEG Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#childmind-institute" class="md-nav__link">
    ChildMind Institute
  </a>
  
    <nav class="md-nav" aria-label="ChildMind Institute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hbn-healthy-brain-networks" class="md-nav__link">
    HBN - Healthy Brain Networks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mipdb-multimodal-resource-for-studying-information-processing-in-the-developing-brain" class="md-nav__link">
    MIPDB - Multimodal Resource for Studying Information Processing in the Developing Brain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#physionet" class="md-nav__link">
    Physionet
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict-patient-repository-for-eeg-data-computational-tools" class="md-nav__link">
    PREDICT - Patient Repository for EEG Data + Computational Tools
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tuh-temple-university-hospital-corpus" class="md-nav__link">
    TUH - Temple University Hospital Corpus
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eegbase" class="md-nav__link">
    EEGbase
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nitrc-neuroimaging-tools-resource-collaboratory" class="md-nav__link">
    NITRC - Neuroimaging Tools &amp; Resource Collaboratory
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#erp-core" class="md-nav__link">
    ERP-CORE
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bnci-horizon-2020" class="md-nav__link">
    BNCI Horizon 2020
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mass-montreal-archive-of-sleep-studies" class="md-nav__link">
    MASS - Montreal Archive of Sleep Studies
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nsrr-national-sleep-research-resource" class="md-nav__link">
    NSRR - National Sleep Research Resource
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-cuban-human-brain-mapping-project" class="md-nav__link">
    The Cuban Human Brain Mapping Project
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemon-leipzig-study-for-mind-body-emotion-interactions" class="md-nav__link">
    LEMON - Leipzig Study for Mind-Body-Emotion Interactions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#peers-the-penn-electrophysiology-of-encoding-and-retrieval-study" class="md-nav__link">
    PEERS - The PENN Electrophysiology of Encoding and Retrieval Study
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lab-specific-data-collections" class="md-nav__link">
    Lab-Specific Data Collections
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-research-tasks-research-systems" class="md-nav__link">
    Individual EEG Datasets - Research Tasks (Research Systems)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-research-tasks-consumer-systems" class="md-nav__link">
    Individual EEG Datasets - Research Tasks (Consumer Systems)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-eeg-datasets-clinical-recordings" class="md-nav__link">
    Individual EEG Datasets - Clinical Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-lists-of-eeg-data" class="md-nav__link">
    Other lists of EEG Data
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#meg-data" class="md-nav__link">
    MEG Data
  </a>
  
    <nav class="md-nav" aria-label="MEG Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#omega-open-meg-archive" class="md-nav__link">
    OMEGA - Open MEG Archive
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hcp-human-connectome-project" class="md-nav__link">
    HCP - Human Connectome Project
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camcan-cambridge-center-for-ageing-neuroscience" class="md-nav__link">
    CAMCAN - Cambridge Center for Ageing Neuroscience
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-meg-datasets" class="md-nav__link">
    Individual MEG Datasets
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#human-intracranial-data" class="md-nav__link">
    Human Intracranial Data
  </a>
  
    <nav class="md-nav" aria-label="Human Intracranial Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mni-open-ieeg-atlas" class="md-nav__link">
    MNI Open iEEG Atlas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ieegorg" class="md-nav__link">
    iEEG.org
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#university-of-pennsylvania-computational-memory-lab" class="md-nav__link">
    University of Pennsylvania Computational Memory Lab
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kai-millers-collection-of-ecog-data" class="md-nav__link">
    Kai Miller's Collection of ECoG Data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-ieeg-datasets-research-recordings" class="md-nav__link">
    Individual iEEG Datasets - Research Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-ieeg-datasets-clinical-recordings" class="md-nav__link">
    Individual iEEG Datasets - Clinical Recordings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#human-single-unit-data" class="md-nav__link">
    Human Single Unit Data
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#animal-lfp-data" class="md-nav__link">
    Animal LFP Data
  </a>
  
    <nav class="md-nav" aria-label="Animal LFP Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neurotycho" class="md-nav__link">
    NeuroTycho
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collaborative-research-in-computational-neuroscience-crcns" class="md-nav__link">
    Collaborative Research in Computational Neuroscience (CRCNS)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lab-specific-data-collections_1" class="md-nav__link">
    Lab-Specific Data Collections
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#individual-datasets" class="md-nav__link">
    Individual Datasets
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavioral-data" class="md-nav__link">
    Behavioral Data
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
  
    
  
  <h1 id="open-datasets-in-electrophysiology">Open Datasets in Electrophysiology<a class="headerlink" href="#open-datasets-in-electrophysiology" title="Permanent link">&para;</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following summary was compiled by <a href='https://github.com/TomDonoghue' target="_blank"> <strong>TomDonoghue</strong> </a>, in this <a href='https://github.com/openlists/ElectrophysiologyData' target="_blank">GitHub repository</a>.</p>
</div>
<p>This is a list of openly available electrophysiological data, including EEG, MEG, ECoG/iEEG, and LFP data.</p>
<p>Datasets and resources listed here should all be openly-accessible for research purposes, requiring, at most, registration for access. Be sure to check the license and/or usage agreements for any datasets you access.</p>
<p>To contribute a new link to a data source or resource, open an issue mentioning it, or a pull request with a link.</p>
<h2 id="table-of-contents">Table of Contents<a class="headerlink" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="#data-formats">Data Formats</a></li>
<li><a href="#repositories">Repositories</a></li>
<li><a href="#eeg-data">EEG Data</a></li>
<li><a href="#meg-data">MEG Data</a></li>
<li><a href="#human-intracranial-data">Human Intracranial Data</a></li>
<li><a href="#animal-lfp-data">Animal LFP Data</a></li>
<li><a href="#behavioral-data">Behavioral Data</a></li>
</ul>
<h2 id="data-formats">Data Formats<a class="headerlink" href="#data-formats" title="Permanent link">&para;</a></h2>
<p>The datasets listed here are not guaranteed to be in any particular format. Whenever possible, using standardized data formats can help make datasets more inter-operable.</p>
<p>Standardized data formats for neurophysiological data include:
- <a href="https://www.nwb.org">Neurodata Without Borders</a>, or NWB, is a general data standard for neurophysiology, with the goal of promoting a common standard for storing, sharing, and archiving data. The NWB project also maintains a list of publicly available <a href="https://www.nwb.org/example-datasets/">NWB datasets</a>.
- <a href="https://bids.neuroimaging.io/">Brain Imaging Data Structure</a>, or BIDS, is a set of data standards for imaging data, including
<a href="https://www.nature.com/articles/sdata201644">MRI</a>,
<a href="https://www.nature.com/articles/s41597-019-0104-8">EEG</a>,
<a href="https://www.nature.com/articles/sdata2018110">MEG</a>, and
<a href="https://www.nature.com/articles/s41597-019-0105-7">iEEG</a>.</p>
<h2 id="repositories">Repositories<a class="headerlink" href="#repositories" title="Permanent link">&para;</a></h2>
<p>There are several repositories, journals, and search engines that can be checked and searched for relevant datasets.</p>
<h4 id="neuroscience-specific-data-repositories">Neuroscience Specific Data Repositories<a class="headerlink" href="#neuroscience-specific-data-repositories" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://openneuro.org/">OpenNeuro</a> is a platform for analyzing and sharing neuroimaging data. Originally focused on MRI datasets, it now includes other modalities, including some electrophysiological data. Data on OpenNeuro is generally organized in BIDS formats.</li>
<li>The <a href="https://gui.dandiarchive.org/#/">DANDI</a> archive ('distributed archives for neurophysiological data integration') is a platform for sharing and processing neurophysiological data. It includes a list of <a href="https://gui.dandiarchive.org/#/dandiset">public datasets</a>. Data on DANDI is generally organized in NWB format.</li>
<li>The <a href="https://dabi.loni.usc.edu/home">DABI</a> repository ('data archive BRAIN initiative') is a platform for storing and processing invasive neurophysiological data, in particular for the BRAIN initiative.</li>
<li>The <a href="https://ebrains.eu/">EBrains</a> platform for the European Union's 'Human Brain Project' includes a data portal with available data, including some extra- and intra-cranial human recordings</li>
</ul>
<h4 id="general-purpose-data-repositories">General Purpose Data Repositories<a class="headerlink" href="#general-purpose-data-repositories" title="Permanent link">&para;</a></h4>
<p>There are a few general purpose repositories that you can search for data:
- <a href="https://zenodo.org/">Zenodo</a> hosts datasets for individual studies. You can find available datasets by searching for 'eeg', 'meg', or similar, and selecting the 'Dataset' tag on the bottom left of the search page.
- <a href="https://osf.io/">Open Science Framework</a> is a platform for supporting open science, and includes data hosting of open-datasets for specific studies. It doesn't seem to be easily searchable by data modality in particular, but does host relevant datasets, some of which are included in the listings below.
- <a href="https://figshare.com">Figshare</a> is a general repository service for a broad range of materials, and includes datasets. You can search for resources, and select 'type' as 'Dataset' to see available datasets.
- <a href="https://datadryad.org">Dryad</a> is a repository service for scientific datasets, and includes data linked to specific papers, including some EEG/MEG/ECoG datasets. There is a search function.
- <a href="https://doi.gin.g-node.org">G-Node Open Data</a> is a repository service for scientific datasets, by G-Node (the German Neuroinformatics Node), built on the <a href="https://gin.g-node.org">G-Node data infrastructure services</a>.
- <a href="https://dataverse.harvard.edu/">Harvard Dataverse</a> is a general-purpose repository for research data, that includes some neuroscience data
- <a href="https://www.scidb.cn/en">Science Data Bank</a> is a general-purpose repository for research data, that includes some neuroscience data
- <a href="https://www.kaggle.com">Kaggle</a> is a private company that hosts data analysis competitions. These competitions typically include a dataset, and they also maintain a repository of <a href="https://www.kaggle.com/datasets">available datasets</a>.</p>
<h4 id="data-journals">Data Journals<a class="headerlink" href="#data-journals" title="Permanent link">&para;</a></h4>
<p>There are journals that specifically describe openly available datasets, and/or mandate that data be openly released, including:</p>
<ul>
<li><a href="https://www.nature.com/sdata/">Scientific Data</a><ul>
<li>A general purpose journal that publishes brief reports on openly available datasets</li>
</ul>
</li>
<li><a href="https://www.journals.elsevier.com/data-in-brief">Data in Brief</a><ul>
<li>A general purpose journal that publishes brief reports on openly available datasets</li>
</ul>
</li>
<li><a href="https://academic.oup.com/gigascience">GigaScience</a><ul>
<li>A general topic journal that publishes papers for which all associated data must be made available</li>
<li>Data is uploaded to their <a href="https://gigadb.org/">GigaDB</a> database, that is searchable</li>
</ul>
</li>
</ul>
<h4 id="data-search-engines">Data Search Engines<a class="headerlink" href="#data-search-engines" title="Permanent link">&para;</a></h4>
<p>Google has a <a href="https://datasetsearch.research.google.com/">dataset search</a> tool that can be used to search for datasets.</p>
<h2 id="eeg-data">EEG Data<a class="headerlink" href="#eeg-data" title="Permanent link">&para;</a></h2>
<p>Openly available electroencephalography (EEG) datasets and large-scale projects with EEG data.</p>
<h3 id="childmind-institute">ChildMind Institute<a class="headerlink" href="#childmind-institute" title="Permanent link">&para;</a></h3>
<p>The <a href="https://childmind.org">ChildMind Institute</a> is a non-profit that, amongst other things, is involved in large-scale research projects that release large datasets.</p>
<h4 id="hbn-healthy-brain-networks">HBN - Healthy Brain Networks<a class="headerlink" href="#hbn-healthy-brain-networks" title="Permanent link">&para;</a></h4>
<p>A large project including rest and task EEG data across a large adult cohort (n=~1000).</p>
<p><a href="https://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/index.html">Home Page</a> -
<a href="https://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/sharing_neuro.html#direct-downloads">Data Portal</a> -
<a href="https://dx.doi.org/10.1038/sdata.2017.181">Paper</a></p>
<h4 id="mipdb-multimodal-resource-for-studying-information-processing-in-the-developing-brain">MIPDB - Multimodal Resource for Studying Information Processing in the Developing Brain<a class="headerlink" href="#mipdb-multimodal-resource-for-studying-information-processing-in-the-developing-brain" title="Permanent link">&para;</a></h4>
<p>A project including rest and task EEG data across a young cohort, ages 6-44 (n=126).</p>
<p><a href="https://fcon_1000.projects.nitrc.org/indi/cmi_eeg/index.html">Home Page</a> -
<a href="https://fcon_1000.projects.nitrc.org/indi/cmi_eeg/eeg.html">Data Portal</a> -
<a href="https://doi.org/10.1038/sdata.2017.40">Paper</a></p>
<h3 id="physionet">Physionet<a class="headerlink" href="#physionet" title="Permanent link">&para;</a></h3>
<p>Physionet is an archive of physiology data, and includes some EEG data under the 'neuroelectric' tag.</p>
<p><a href="https://physionet.org">Home Page</a> -
<a href="https://physionet.org/physiobank/database/#neuro">Data Portal</a> -
<a href="https://doi.org/10.1161/01.CIR.101.23.e215">Paper</a></p>
<p>Available datasets include:
- EEG Motor Movement / Imagery (n=109):
<a href="https://www.physionet.org/pn4/eegmmidb/">Data</a></p>
<h3 id="predict-patient-repository-for-eeg-data-computational-tools">PREDICT - Patient Repository for EEG Data + Computational Tools<a class="headerlink" href="#predict-patient-repository-for-eeg-data-computational-tools" title="Permanent link">&para;</a></h3>
<p>PREDICT is a repository for EEG data, focused on patient data (collected in research settings).</p>
<p><a href="http://predict.cs.unm.edu">Home Page</a> -
<a href="http://predict.cs.unm.edu/downloads.php">Data Portal</a> -
<a href="https://doi.org/10.3389/fninf.2017.00067">Paper</a></p>
<h3 id="tuh-temple-university-hospital-corpus">TUH - Temple University Hospital Corpus<a class="headerlink" href="#tuh-temple-university-hospital-corpus" title="Permanent link">&para;</a></h3>
<p>A large collection of EEG recorded in clinical settings (hospital data).</p>
<p><a href="https://www.isip.piconepress.com/projects/tuh_eeg/">Home Page</a> -
<a href="https://www.isip.piconepress.com/projects/tuh_eeg/html/request_access.php">Data Portal</a> -
<a href="https://doi.org/10.3389/fnins.2016.00196">Paper</a></p>
<p>The TUH includes multiple (described <a href="https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml">here</a>), including:
- The TUH Abnormal EEG Corpus (TUAB), with annotatations for if recordings are normal or abnormal
- The TUH EEG Artifact Corpus (TUAR), with annotations of different artifacts
- The TUH Epilepsy Corpus (TUEP), with a selected of subjects with and without epilepsy
- The TUH EEG Events Corpus (TUEV), with annotations of specific events (sharp waves, epileptiform discharges, etc)
- The TUH EEG Seizure Corpus (TUSZ), with annotations for seizures
- The TUH EEG Slowing Corpus (TUSL), with annotations for slowing events</p>
<h3 id="eegbase">EEGbase<a class="headerlink" href="#eegbase" title="Permanent link">&para;</a></h3>
<p>EEGbase is a database for electrophysiological data.</p>
<p><a href="https://eegdatabase.kiv.zcu.cz/">Home Page</a> -
<a href="https://doi.org/10.14311/NNW.2012.22.016">Paper</a></p>
<p>Note: you need to register, and the website has a 'Add to Cart' &amp; 'Complete Order' workflow, but the datasets are free.</p>
<p>Available datasets include:
- ERP Dataset, Visual P300 Paradigm (n=20):
<a href="https://doi.org/10.1186/2047-217X-3-35">Paper</a>
  - Note that this data is also available on GigaDB
- ERP OddBall Design, Number Guessing Game  (n=250):
<a href="https://doi.org/10.1038/sdata.2016.121">Paper</a>
- ERP dataset on Developmental Coordination Disorder (n=32):
<a href="https://doi.org/10.1093/gigascience/gix002">Paper</a>
- EEG activity using a driving simulator (n=15):
<a href="https://doi.org/10.5220/0006249504410450">Paper</a></p>
<h3 id="nitrc-neuroimaging-tools-resource-collaboratory">NITRC - Neuroimaging Tools &amp; Resource Collaboratory<a class="headerlink" href="#nitrc-neuroimaging-tools-resource-collaboratory" title="Permanent link">&para;</a></h3>
<p>NITRC is a general purpose repository community board for neuroimaging tools, resources, and datasets. It is generally more focused on tools than datasets, but it does contain some available EEG datasets.</p>
<p><a href="https://www.nitrc.org/">Home Page</a> -
<a href="https://doi.org/10.1016/j.neuroimage.2015.05.074">Paper</a></p>
<p>Available datasets include:
- Visual Oddball Task (n=18):
<a href="https://www.nitrc.org/projects/vep_eeg_raw">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2017.11.032">Paper</a>
- Categorization Task (n=14):
<a href="https://www.nitrc.org/projects/eegdataanimal">Data</a>
- Resting State fMRI/EEG (n=8):
<a href="https://www.nitrc.org/projects/cwleegfmri_data">Data</a></p>
<h3 id="erp-core">ERP-CORE<a class="headerlink" href="#erp-core" title="Permanent link">&para;</a></h3>
<p>ERP-CORE (Compendium of Open Resources and Experiments) is a resource with experiment paradigms and scripts, example data &amp; example processing scripts for ERPs, including the N170, mismatch negativity (MMN), N2pc, N400, P300, lateralized readiness potential (LRP), and error-related negativity (ERN).</p>
<p><a href="https://osf.io/thsqg/">Data</a> -
<a href="https://doi.org/10.31234/osf.io/4azqm">Paper</a></p>
<h3 id="bnci-horizon-2020">BNCI Horizon 2020<a class="headerlink" href="#bnci-horizon-2020" title="Permanent link">&para;</a></h3>
<p>A collection of BCI related EEG datasets.</p>
<p><a href="http://bnci-horizon-2020.eu/database/data-sets">Home Page</a></p>
<h3 id="mass-montreal-archive-of-sleep-studies">MASS - Montreal Archive of Sleep Studies<a class="headerlink" href="#mass-montreal-archive-of-sleep-studies" title="Permanent link">&para;</a></h3>
<p>MASS is a collection of whole night sleep recordings from approximately 200 participants, from hospital based sleep laboratories.</p>
<p><a href="https://massdb.herokuapp.com/en/">Home Page</a> -
<a href="https://massdb.herokuapp.com/en/get-access/">Data Portal</a> -
<a href="https://doi.org/10.1111/jsr.12169">Paper</a></p>
<h3 id="nsrr-national-sleep-research-resource">NSRR - National Sleep Research Resource<a class="headerlink" href="#nsrr-national-sleep-research-resource" title="Permanent link">&para;</a></h3>
<p>NSRR is a resource offering large collections of physiological signals, including polysomnography recordings with EEG from research studies and clinical collections.</p>
<p><a href="https://sleepdata.org/">Home Page</a> -
<a href="https://sleepdata.org/datasets">Data Portal</a> -
<a href="https://doi.org/10.5665/sleep.5774">Paper</a></p>
<h3 id="the-cuban-human-brain-mapping-project">The Cuban Human Brain Mapping Project<a class="headerlink" href="#the-cuban-human-brain-mapping-project" title="Permanent link">&para;</a></h3>
<p>The CHBMP is an open dataset from 282 young and middle age healthy participants, including resting state EEG, and during hyperventilation.</p>
<p><a href="https://www.synapse.org/#!Synapse:syn22324937">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-00829-7">Paper</a></p>
<h3 id="lemon-leipzig-study-for-mind-body-emotion-interactions">LEMON - Leipzig Study for Mind-Body-Emotion Interactions<a class="headerlink" href="#lemon-leipzig-study-for-mind-body-emotion-interactions" title="Permanent link">&para;</a></h3>
<p>A large multimodal dataset (n=228), with cross-sectional sampling of young and old participants, and including MRI, EEG, physiological, clinical and cognitive measures.</p>
<p><a href="https://doi.org/10.15387/fcp_indi.mpi_lemon">Homepage</a> -
<a href="http://fcon_1000.projects.nitrc.org/indi/retro/MPI_LEMON/downloads/download_EEG.html">Data</a> -
<a href="https://doi.org/10.1038/sdata.2018.308">Paper</a></p>
<h3 id="peers-the-penn-electrophysiology-of-encoding-and-retrieval-study">PEERS - The PENN Electrophysiology of Encoding and Retrieval Study<a class="headerlink" href="#peers-the-penn-electrophysiology-of-encoding-and-retrieval-study" title="Permanent link">&para;</a></h3>
<p>A large dataset of EEG data (n&gt;300), covering 5 experiments in which subjects perform memory tasks, encoding and retrieving stimuli. </p>
<p><a href="https://memory.psych.upenn.edu/Penn_Electrophysiology_of_Encoding_and_Retrieval_Study">Homepage</a> - 
<a href="https://memory.psych.upenn.edu/Data_Archive">Data</a> -
<a href="https://psyarxiv.com/bu5x8/">Paper</a></p>
<h3 id="lab-specific-data-collections">Lab-Specific Data Collections<a class="headerlink" href="#lab-specific-data-collections" title="Permanent link">&para;</a></h3>
<p>The following labs are collections of datasets from particular labs:
- Narayanan lab: predominantly EEG datasets collected from humans, including Parkinson's patients:
<a href="https://narayanan.lab.uiowa.edu/article/datasets">Datasets</a> -
<a href="https://narayanan.lab.uiowa.edu/">Lab website</a></p>
<h3 id="individual-eeg-datasets-research-tasks-research-systems">Individual EEG Datasets - Research Tasks (Research Systems)<a class="headerlink" href="#individual-eeg-datasets-research-tasks-research-systems" title="Permanent link">&para;</a></h3>
<p>The following are datasets collected with research EEG systems:
- Motor Imagery BCI Data (n=52):
<a href="http://gigadb.org/dataset/100295">Data</a> -
<a href="https://doi.org/10.5524/100295">Paper</a>
- Simultaneous EEG &amp; NIRS during cognitive tasks (n=26):
<a href="https://depositonce.tu-berlin.de//handle/11303/6271.2">Data</a> -
<a href="https://doi.org/10.1038/sdata.2018.3">Paper</a>
- EEG during grasp and lift (n=12):
<a href="https://doi.org/10.6084/m9.figshare.988376">Data</a> -
<a href="https://doi.org/10.1038/sdata.2014.47">Paper</a>
- EEG, MEG &amp; fMRI data with perceptual task (n=19):
<a href="https://openneuro.org/datasets/ds000117/versions/00004">Data</a> -
<a href="https://doi.org/10.1038/sdata.2015.1">Paper</a>
- EEG data with TMS with visual perception task (n=16):
<a href="https://datadryad.org/resource/doi:10.5061/dryad.1nr07">Data</a> -
<a href="https://doi.org/10.1038/sdata.2016.65">Paper</a>
- EEG with Motion Capture during treadmill walking (n=8):
<a href="https://doi.org/10.6084/m9.figshare.c.3894013.v1">Data</a> -
<a href="https://doi.org/10.1038/sdata.2018.74">Paper</a>
- EEG data with a visual spatial attention task (n=45):
<a href="https://osf.io/bwzfj">Data</a> -
<a href="https://doi.org/10.1152/jn.00860.2015">Paper</a>
- EEG data with a visual working memory task, ERP design (n=104):
<a href="https://osf.io/a65xz/">Data</a> -
<a href="https://doi.org/10.1093/cercor/bhx336">Paper</a>
- EEG data with a visual working memory task, CDA design (n=76):
<a href="https://osf.io/8xuk3">Data</a> -
<a href="https://doi.org/10.1162/jocn_a_01233">Paper</a>
- EEG data with a covert visual spatial attention task (n=50):
<a href="https://osf.io/m64ue">Data</a> -
<a href="https://doi.org/10.1177/0956797617699167">Paper</a>
- OpenMIIR: EEG data during music perception and imagination (n=10):
<a href="http://www.owenlab.uwo.ca/research/the_openmiir_dataset.html">Home Page</a> -
<a href="http://www.ling.uni-potsdam.de/mlcog/OpenMIIR-RawEEG_v1/">Data</a>
- EEG data from subjects napping after a working memory task (n=22):
<a href="https://osf.io/chav7/">Data</a> -
<a href="https://doi.org/10.1016/j.compbiomed.2017.08.030">Paper</a>
- DEAP: Database for Emotion Analysis, EEG data + video recording, while watching videos (n=32):
<a href="http://www.eecs.qmul.ac.uk/mmv/datasets/deap/">Data</a> -
<a href="https://doi.org/10.1109/T-AFFC.2011.15">Paper</a>
- A collection of EEG tasks with speech studies (n=84, split across 5 tasks):
<a href="https://doi.org/10.5061/dryad.070jc">Data</a> -
<a href="https://doi.org/10.1016/j.cub.2018.01.080">Paper</a>
- EEG recordings with concurrent EMG while doing everyday tasks (n=27):
<a href="http://researchdata.gla.ac.uk/676/">Data</a>
- Multi-modal (EEG, EMG, EOG) recordings during movement tasks (n=25):
<a href="http://dx.doi.org/10.5524/100788">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giaa098">Paper</a>
- EEG BCI recordings during mental imagery, across sessions &amp; interaction paradigms (n=13):
<a href="https://doi.org/10.6084/m9.figshare.c.3917698.v1">Data</a> -
<a href="https://doi.org/10.1038/sdata.2018.211">Paper</a>
- EEG resting state data, with MRI anatomical scans (n=12):
<a href="https://doi.org/10.5061/dryad.v9f16">Data</a> -
<a href="https://doi.org/10.1371/journal.pone.0146845">Paper</a>
- Multi-day, multi band SSVEP dataset for BCI applications (n=30):
<a href="https://doi.org/10.5524/100660">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giz133">Paper</a>
- Multi-day, dataset from sleep (naps) recorded after visual working memory task (n=22):
<a href="https://osf.io/chav7/">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2018.04.073">Paper</a>
- EEG dataset from subjects viewing images (n=24):
<a href="https://doi.org/10.12751/g-node.bcccab">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2019.103857">Paper</a>
- EEG data with resting state and visual working memory task (n=43):
<a href="https://openneuro.org/datasets/ds003420/versions/1.0.2">Dataset1</a> -
<a href="https://openneuro.org/datasets/ds003421/versions/1.0.2">Dataset2</a> -
<a href="https://doi.org/10.1038/s41597-021-00821-1">Paper</a>
- EEG from participants playing an 8-bit style video game (n=17):
<a href="https://openneuro.org/datasets/ds003517/versions/1.1.0">Data</a> -
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811916001932?via%3Dihub">Paper</a>
- An EEG/BCI dataset across multiple paradigms and recording sessions (n=54):
<a href="http://dx.doi.org/10.5524/100542">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giz002">Paper</a>
- A large EEG dataset with a simple gambling task (n=500):
<a href="https://osf.io/65x4v/">Data</a> -
<a href="https://doi.org/10.1111/psyp.13722">Paper</a>
- A dataset comparing different EEG systems, including 3 sessions per participant (n=14):
<a href="https://www.cs.colostate.edu/eeg/main/data/2011-12_BCI_at_CSU">Data</a>
- An EEG/BCI dataset for inner speech recognition (n=10):
<a href="https://openneuro.org/datasets/ds003626/versions/1.0.1">Data</a> -
<a href="https://www.biorxiv.org/content/10.1101/2021.04.19.440473v1">Paper</a>
- An EEG/BCI sensorimotor dataset, with longitudinal data (n=62):
<a href="https://doi.org/10.6084/m9.figshare.13123148">Data</a> -
<a href="https://www.nature.com/articles/s41597-021-00883-1">Paper</a>
- An EEG dataset of with rapid serial visual presentation (n=50):
<a href="https://doi.org/10.18112/openneuro.ds003825.v1.1.0">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-01102-7">Paper</a>
- A dataset of hdEEG during transcranial electrical stimulation (n=20):
<a href="https://zenodo.org/record/4456079">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-01046-y">Paper</a>
- Mobile BCI dataset of scalp and ear EEG with ERP and SSVEP paradigms while standing and moving (n=24):
<a href="https://doi.org/10.17605/OSF.IO/R7S9Bhttps">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-01094-4">Paper</a>
- Polysomnography dataset, including 3 EEG channels, for sleep apnea studies (n=212):
<a href="https://doi.org/10.11922/sciencedb.00345">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-00977-w">Paper</a>
- EEG and EMG data during perturbed walking and standing (n=30):
<a href="https://doi.org/10.1016/j.dib.2021.107635">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2021.107635">Paper</a>
- EEG data in subjects with claustrophobia, and controls, resting state in different sized rooms (n=22):
<a href="https://doi.org/10.1016/j.dib.2021.107733">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2021.107733">Paper</a>
- A dataset of arm motion in healthy and post-stroke subjects, with some EEG data (n=45 with EEG):
<a href="https://doi.org/10.7910/DVN/FU3QZ9">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giab043">Paper</a>
- A dataset of EEG and behavioral data with a visual working memory task in virtual reality (n=47):
<a href="https://osf.io/s9xmu/">Data</a> -
<a href="https://doi.org/10.1016/j.dib.2022.107827">Paper</a>
- The Nencki-Symfonia EEG/ERP dataset: high-density electroencephalography (EEG) dataset obtained at the Nencki Institute of Experimental Biology from a sample of 42 healthy young adults with three cognitive tasks: (1) an extended Multi-Source Interference Task (MSIT+) with control, Simon, Flanker, and multi-source interference trials; (2) a 3-stimuli oddball task with frequent standard, rare target, and rare distractor stimuli; (3) a control, simple reaction task (SRT); and additionally (4) a resting-state protocol (REST)
<a href="http://doi.org/10.5524/100990">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giac015">Paper</a></p>
<h3 id="individual-eeg-datasets-research-tasks-consumer-systems">Individual EEG Datasets - Research Tasks (Consumer Systems)<a class="headerlink" href="#individual-eeg-datasets-research-tasks-consumer-systems" title="Permanent link">&para;</a></h3>
<p>The following are available EEG datasets collected with consumer EEG systems:
- MNIST of Brain Data from MindBigData (n=1 with 1.2 million trials):
<a href="http://mindbigdata.com/opendb/index.html">Data</a>
- ImageNet of the Brain from MindBigData (n=1 with 70,000 trials):
<a href="http://mindbigdata.com/opendb/imagenet.html">Data</a></p>
<h3 id="individual-eeg-datasets-clinical-recordings">Individual EEG Datasets - Clinical Recordings<a class="headerlink" href="#individual-eeg-datasets-clinical-recordings" title="Permanent link">&para;</a></h3>
<p>The following are available EEG datasets collected in the context of clinical recordings / disease states:
- Resting state data from Parkinson's patients, with healthy controls (n=28):
<a href="https://doi.org/10.18112/openneuro.ds002778.v1.0.5">Data</a> - 
<a href="https://doi.org/10.1016/j.nicl.2013.07.013">Paper</a>
- Data from neonatal EEG recordings with seizure annotations (n=79):
<a href="https://doi.org/10.5281/zenodo.2547147">Data</a> - 
<a href="https://doi.org/10.1038/sdata.2019.39">Paper</a>
- A dataset of EEG recordings from pediatric subjects with intractable seizures (n=22):
<a href="https://physionet.org/content/chbmit/1.0.0/">Data</a> - 
<a href="https://dspace.mit.edu/handle/1721.1/54669">Paper</a></p>
<h3 id="other-lists-of-eeg-data">Other lists of EEG Data<a class="headerlink" href="#other-lists-of-eeg-data" title="Permanent link">&para;</a></h3>
<p>There are some other lists of available EEG data, including:
- A publicly <a href="https://github.com/meagmohit/EEG-Datasets">curated list</a> list of EEG data
- The <a href="https://sccn.ucsd.edu/~arno/fam2data/publicly_available_EEG_data.html">SCCN list</a> of public EEG data</p>
<h2 id="meg-data">MEG Data<a class="headerlink" href="#meg-data" title="Permanent link">&para;</a></h2>
<p>Openly available magnetoencephalography (MEG) datasets and large-scale projects with MEG data.</p>
<h3 id="omega-open-meg-archive">OMEGA - Open MEG Archive<a class="headerlink" href="#omega-open-meg-archive" title="Permanent link">&para;</a></h3>
<p>OMEGA is a open-access repository for MEG data, in which individual researchers can deposit their data.</p>
<p><a href="https://www.mcgill.ca/bic/resources/omega">Home Page</a> -
<a href="https://doi.org/10.1016/j.neuroimage.2015.04.028">Paper</a></p>
<h3 id="hcp-human-connectome-project">HCP - Human Connectome Project<a class="headerlink" href="#hcp-human-connectome-project" title="Permanent link">&para;</a></h3>
<p>The Human-Connectome Project is a large, multi-site project, mostly focused on MRI, that also includes a subset of MEG data.</p>
<p><a href="https://www.humanconnectome.org/study/hcp-young-adult">Home Page</a></p>
<h3 id="camcan-cambridge-center-for-ageing-neuroscience">CAMCAN - Cambridge Center for Ageing Neuroscience<a class="headerlink" href="#camcan-cambridge-center-for-ageing-neuroscience" title="Permanent link">&para;</a></h3>
<p>CAMCAN includes task &amp; rest MEG data from a large cohort, balanced in age from age 18-88 (n=652).</p>
<p><a href="https://camcan-archive.mrc-cbu.cam.ac.uk/">Home Page</a></p>
<h3 id="individual-meg-datasets">Individual MEG Datasets<a class="headerlink" href="#individual-meg-datasets" title="Permanent link">&para;</a></h3>
<p>The following are openly available datasets with MEG data:
- 'Mother of unification studies' (MOUS) dataset, resting state and language task (n=204):
<a href="https://data.donders.ru.nl/collections/di/dccn/DSC_3011020.09_236?0">Data</a> -
<a href="https://www.nature.com/articles/s41597-019-0020-y">Paper</a>
- Classification of Multimodal Stimulus Presentation - Visual &amp; Auditory (n=52):
<a href="https://osf.io/m25n4/">Data</a> -
<a href="https://doi.org/10.1371/journal.pcbi.1005938">Paper</a>
- Multi-subject, multimodal face processing dataset including fMRI, MEG, EEG (n=16):
<a href="https://openneuro.org/datasets/ds000117/versions/1.0.0">Data</a> -
<a href="https://doi.org/10.1038/sdata.2015.1">Paper</a>
- Decaf dataset, movie clip watching (n=30):
<a href="http://mhug.disi.unitn.it/wp-content/DECAF/DECAF.html">Data</a>
- MEG data during four mental imagery tasks, for BCI analyses (n=17):
<a href="https://doi.org/10.6084/m9.figshare.c.5101544">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-00899-7">Paper</a></p>
<h2 id="human-intracranial-data">Human Intracranial Data<a class="headerlink" href="#human-intracranial-data" title="Permanent link">&para;</a></h2>
<p>This section contains intracranial EEG (iEEG) data from humans participants (collected in clinical contexts), including electrocorticography (ECoG) and stereo-EEG (sEEG) recordings, as well as any available human single unit data.</p>
<h3 id="mni-open-ieeg-atlas">MNI Open iEEG Atlas<a class="headerlink" href="#mni-open-ieeg-atlas" title="Permanent link">&para;</a></h3>
<p>The MNI Open iEEG atlas is a multi-center repository of curated iEEG data, including resting state (n=106) and sleep (n=91) data.</p>
<p><a href="https://mni-open-ieegatlas.research.mcgill.ca">Home Page</a> -
<a href="https://doi.org/10.1093/brain/awy035">Paper (rest data)</a> -
<a href="https://doi.org/10.1002/ana.25651">Paper (sleep data)</a></p>
<h3 id="ieegorg">iEEG.org<a class="headerlink" href="#ieegorg" title="Permanent link">&para;</a></h3>
<p>iEEG.org is an NIH supported repository of intracranial EEG data.</p>
<p><a href="https://www.ieeg.org">Home Page</a></p>
<h3 id="university-of-pennsylvania-computational-memory-lab">University of Pennsylvania Computational Memory Lab<a class="headerlink" href="#university-of-pennsylvania-computational-memory-lab" title="Permanent link">&para;</a></h3>
<p>The cognitive electrophysiology data portal has a list of publications that have available electrophysiological data.</p>
<p><a href="https://memory.psych.upenn.edu/Electrophysiological_Data">Home Page</a></p>
<p>The 'Restoring Active Memory' project is coordinate collection of ECoG data, with memory tasks (n=251).</p>
<p><a href="https://memory.psych.upenn.edu/RAM">Home Page</a></p>
<h3 id="kai-millers-collection-of-ecog-data">Kai Miller's Collection of ECoG Data<a class="headerlink" href="#kai-millers-collection-of-ecog-data" title="Permanent link">&para;</a></h3>
<p>A collection of ECoG recordings, including 204 sessions from across 16 different tasks (n=34).</p>
<p><a href="https://purl.stanford.edu/zk881ps0522">Home Page</a> -
<a href="https://doi.org/10.1152/jn.00113.2017">Paper</a></p>
<h3 id="individual-ieeg-datasets-research-recordings">Individual iEEG Datasets - Research Recordings<a class="headerlink" href="#individual-ieeg-datasets-research-recordings" title="Permanent link">&para;</a></h3>
<p>The following are openly available datasets with human intracranial data:
- Multicenter resting state and sleep ECoG data, annotated for artifacts (n=39):
<a href="https://doi.org/10.6084/m9.figshare.c.4681208.v1">Data</a> -
<a href="https://doi.org/10.1038/s41597-020-0532-5">Paper</a>
- ECoG data from a study looking at sensorimotor alpha and beta activity (n=3):
<a href="https://osf.io/z4hfm/">Data</a> -
<a href="https://doi.org/10.7554/eLife.48065">Paper</a>
- Multimodal dataset of iEEG &amp; fMRI data while watching a short movie (n=51 iEEG subjects):
<a href="https://openneuro.org/datasets/ds003688">Data</a> - 
<a href="https://doi.org/10.1038/s41597-022-01173-0">Paper</a>
- A dataset of long-term iEEG recordings of naturalistic data &amp; pose estimation (n=12):
<a href="https://gui.dandiarchive.org/#/dandiset/000055/">Data</a> -
<a href="https://www.biorxiv.org/content/10.1101/2021.07.26.453884v1.abstract">Paper</a>
- Data from subjects with simultaneous EEG recordings and intracranial electrical stimulation (n=7):
<a href="https://doi.org/10.25493/NXN2-05W">Data</a> -
<a href="https://doi.org/10.1038/s41597-020-0467-x">Paper</a>
- Intracranial data during visual scene recognition of famous landmarks (n=50):
<a href="https://dabi.loni.usc.edu/dsi/1U01NS098981">Data</a> -
<a href="https://doi.org/10.1038/s41597-022-01125-8">Paper</a>
- Intracranial data during memory tasks with pupillometry (n=10):
<a href="https://doi.org/10.25493/GKNT-T3X">Data</a> -
<a href="https://www.nature.com/articles/s41597-021-01099-z">Paper</a>
- Intracranial data investigating responses to single-pulse stimulation (n=52):
<a href="https://dabi.loni.usc.edu/dsi/W4SNQ7HR49RL">Data</a> - 
<a href="https://doi.org/10.1016/j.brs.2022.02.017">Paper</a></p>
<h3 id="individual-ieeg-datasets-clinical-recordings">Individual iEEG Datasets - Clinical Recordings<a class="headerlink" href="#individual-ieeg-datasets-clinical-recordings" title="Permanent link">&para;</a></h3>
<p>The following are openly available datasets that contain seizures and/or are annotated for epilepsy:
- A multicenter collection of iEEG data, including seizures (n=30):
<a href="https://openneuro.org/datasets/ds003029/versions/1.0.3">Data</a> - 
<a href="https://doi.org/10.1038/s41593-021-00901-w">Paper</a>
- A dataset of iEEG recordings from epilepsy patients, organized in BIDS (n=12):
<a href="https://doi.org/10.18112/openneuro.ds003844.v1.0.3">Data</a> - 
<a href="https://doi.org/10.1007/s12021-022-09567-6">Paper</a></p>
<h3 id="human-single-unit-data">Human Single Unit Data<a class="headerlink" href="#human-single-unit-data" title="Permanent link">&para;</a></h3>
<p>Available datasets with single unit data from humans:
- Human single units with a declarative memory task (n=59):
<a href="https://osf.io/hv7ja/">Data</a> -
<a href="https://doi.org/10.1038/s41597-020-0415-9">Paper</a> -
<a href="https://github.com/rutishauserlab/recogmem-release-NWB">Associated Code</a>
- Human single units with a verbal working memory task, also including iEEG data (n=9):
<a href="https://gin.g-node.org/USZ_NCH/Human_MTL_units_scalp_EEG_and_iEEG_verbal_WM">Data</a> -
<a href="https://www.nature.com/articles/s41597-020-0364-3">Paper</a>
- Human single units from the amygdala, with visual presentation of neutral and aversive stimuli (n=9):
<a href="https://doi.gin.g-node.org/10.12751/g-node.270z59/">Data</a> -
<a href="https://doi.org/10.1038/s41597-020-00790-x">Paper</a>
- Single unit data from neuropixel probes in human cortex (n=3):
<a href="https://doi.org/10.5061/dryad.d2547d840">Data</a> -
<a href="https://doi.org/10.1101/2021.06.20.449152">Paper</a></p>
<h2 id="animal-lfp-data">Animal LFP Data<a class="headerlink" href="#animal-lfp-data" title="Permanent link">&para;</a></h2>
<p>Openly available animal datasets with local field potential (LFP) data, including multi-electrode arrays, animal ECoG, single-units, or similar recordings.</p>
<h3 id="neurotycho">NeuroTycho<a class="headerlink" href="#neurotycho" title="Permanent link">&para;</a></h3>
<p>NeuroTycho is as collection of mostly monkey ECoG data.</p>
<p><a href="http://neurotycho.org">Home Page</a></p>
<h3 id="collaborative-research-in-computational-neuroscience-crcns">Collaborative Research in Computational Neuroscience (CRCNS)<a class="headerlink" href="#collaborative-research-in-computational-neuroscience-crcns" title="Permanent link">&para;</a></h3>
<p>A collection of data, including extra-cellular recordings, and some ECoG &amp; iEEG, from various species.</p>
<p><a href="https://crcns.org">Home Page</a> -
<a href="https://crcns.org/data-sets/">Data Portal</a> -
<a href="https://doi.org/10.1007/s12021-008-9009-y">Paper</a></p>
<h3 id="lab-specific-data-collections_1">Lab-Specific Data Collections<a class="headerlink" href="#lab-specific-data-collections_1" title="Permanent link">&para;</a></h3>
<p>The following labs are collections of datasets from particular labs:</p>
<ul>
<li>Buzsáki lab: electrophysiological datasets collected from rodents:
<a href="https://buzsakilab.nyumc.org/datasets/">Datasets</a> -
<a href="https://buzsakilab.com/wp/">Lab website</a></li>
<li>Giocomo Lab: neural data recorded from rodents:
<a href="https://giocomolab.weebly.com/data.html">Datasets</a> -
<a href="https://giocomolab.weebly.com/">Lab website</a></li>
</ul>
<h3 id="individual-datasets">Individual Datasets<a class="headerlink" href="#individual-datasets" title="Permanent link">&para;</a></h3>
<p>The following are available individual LFP and related datasets:</p>
<ul>
<li>LFP during during delayed reach-to-grasp task (macaque monkey, n=2):
<a href="https://gin.g-node.org/INT/multielectrode_grasp">Data</a> -
<a href="https://doi.org/10.1038/sdata.2018.55">Paper</a></li>
<li>Raw LFP recordings and spiking data during anesthesia (rats, n=20):
<a href="https://gin.g-node.org/UlbertLab/High_Resolution_Cortical_Spikes">Data</a> -
<a href="https://doi.org/10.1038/s41597-021-00970-3">Paper</a></li>
<li>Whole-cell intracellular recordings from somatosensory cortex (mouse, n=195):
<a href="https://doi.org/10.5524/100535">Data</a> -
<a href="https://doi.org/10.1093/gigascience/giy147">Paper</a></li>
<li>High channel count (1024) Utah array recordings in macaque V1 and V4 from resting state (n=2):
<a href="https://doi.gin.g-node.org/10.12751/g-node.i20kyh/">Data</a> -
<a href="https://doi.org/10.1038/s41597-022-01180-1">Paper</a></li>
</ul>
<h2 id="behavioral-data">Behavioral Data<a class="headerlink" href="#behavioral-data" title="Permanent link">&para;</a></h2>
<p>This list does not currently track behaviour-only data.</p>
<p>See this <a href="https://nivlab.github.io/opendata/">list of available behavioral data</a>.</p>
<p><br>
<br>
<br></p>
  
    
  

              </article>
            </div>
          
          
        </div>
        
      </main>
      
  <!--
  Copyright (c) 2016-2020 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->



<!-- Application footer -->
<footer class="md-footer">

  <!-- Link to previous and/or next page -->
  
    <div class="md-footer-nav">
      <nav
        class="md-footer-nav__inner md-grid"
        aria-label=""
      >

        <!-- Link to previous page -->
        
          <a
            href="other_software.html"
            title="Other Software"
            class="md-footer-nav__link md-footer-nav__link--prev"
            rel="prev"
          >
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Other Software
              </div>
            </div>
          </a>
        

        <!-- Link to next page -->
        
      </nav>
    </div>
  

  <!-- Further information -->
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">

      <!-- Copyright and theme information -->
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2022 Greydon Gilmore
          </div>
        
      </div>

      <!-- Social links -->
      <div class="md-social">
  
</div>
    </div>
  </div>
</footer>

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.b425cdc4.min.js"></script>
      
        
          <script src="https://unpkg.com/mermaid@8.4.4/dist/mermaid.min.js"></script>
        
      
        
          <script src="javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
    
  </body>
</html>